{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-26T09:25:31.816401500Z",
     "start_time": "2024-02-26T09:25:31.226566100Z"
    }
   },
   "id": "initial_id",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\胡逸凡\\AppData\\Roaming\\Python\\Python310\\site-packages\\pyfolio\\pos.py:26: UserWarning: Module \"zipline.assets\" not found; mutltipliers will not be applied to position notionals.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from stable_baselines3.common.logger import configure\n",
    "from finrl.meta.data_processor import DataProcessor\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "\n",
    "import itertools"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T09:25:36.763893500Z",
     "start_time": "2024-02-26T09:25:31.813268500Z"
    }
   },
   "id": "441d2ae5ec60bdaf",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from finrl import config\n",
    "from finrl import config_tickers\n",
    "import os\n",
    "from finrl.main import check_and_make_directories\n",
    "from finrl.config import (\n",
    "    DATA_SAVE_DIR,\n",
    "    TRAINED_MODEL_DIR,\n",
    "    TENSORBOARD_LOG_DIR,\n",
    "    RESULTS_DIR,\n",
    "    INDICATORS,\n",
    ")\n",
    "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T09:25:36.766894500Z",
     "start_time": "2024-02-26T09:25:36.752276700Z"
    }
   },
   "id": "ef35678f597d1204",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.read_csv('day_level_dataset/ccso_2023-06-01_2023-12-31.csv')\n",
    "df = df.sort_values(['dt','kdcode'])\n",
    "df = df.fillna(0)\n",
    "df.rename(columns={'dt':'date', 'kdcode':'tic'}, inplace=True)\n",
    "df.rename(columns={'Last':'last', 'HighPrice':'high', 'Volume':'volume', 'TurnOver':'turnover', 'OpenPrice':'open', 'LowPrice':'low', }, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T09:25:37.113346600Z",
     "start_time": "2024-02-26T09:25:36.765894200Z"
    }
   },
   "id": "d247a20a5614ec08",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "             date          tic      close       last     volume   turnover  \\\n6624   2023-06-01  600000.XSHG   7.275556   7.294183  19.623353  21.611260   \n19008  2023-06-01  600008.XSHG   3.050000   3.063920  20.324832  21.443540   \n22608  2023-06-01  600015.XSHG   5.730000   5.754824  19.498933  21.249332   \n22752  2023-06-01  600017.XSHG   3.010000   3.008880  19.648348  20.747041   \n9360   2023-06-01  600018.XSHG   5.260000   5.285801  18.915014  20.580564   \n...           ...          ...        ...        ...        ...        ...   \n15551  2023-12-29  688728.XSHG  20.477000  20.391906  18.222323  21.237417   \n27071  2023-12-29  688772.XSHG  22.010556  21.908441  18.629867  21.713466   \n19871  2023-12-29  688777.XSHG  45.341000  45.372965  18.358121  22.172390   \n7919   2023-12-29  688819.XSHG  27.920000  28.023930  17.149986  20.484693   \n17711  2023-12-29  688981.XSHG  53.020000  53.125762  18.828473  22.801503   \n\n        open       high        low   TotalNo  ...    BidVol6       Bid7  \\\n6624    7.33   7.347208   7.267917  4.449198  ...  15.377164   7.138017   \n19008   3.08   3.087250   3.040375  4.933034  ...  16.838710   2.960492   \n22608   5.77   5.806542   5.711750  4.427388  ...  15.420127   5.618904   \n22752   2.99   3.032292   2.961583  4.365749  ...  16.327169   2.908928   \n9360    5.28   5.309917   5.269542  4.288460  ...  14.963574   5.155424   \n...      ...        ...        ...       ...  ...        ...        ...   \n15551  20.65  20.690000  20.181583  4.068172  ...  11.859839  20.063560   \n27071  21.75  22.029250  21.511042  4.173233  ...  11.793579  21.555735   \n19871  45.30  45.671167  45.052417  4.062596  ...  11.647429  44.733479   \n7919   28.00  28.247083  27.862750  3.259858  ...  11.430077  27.599237   \n17711  53.00  53.500000  52.889250  4.656972  ...  11.816843  52.389493   \n\n         BidVol7       Bid8    BidVol8       Bid9    BidVol9      Bid10  \\\n6624   15.199319   7.128142  14.884772   7.118267  14.731421   7.108392   \n19008  16.670304   2.950615  16.292827   2.940738  15.983040   2.930861   \n22608  15.370532   5.609029  15.119865   5.599154  14.938520   5.589279   \n22752  16.151398   2.899053  15.610075   2.889178  15.203544   2.879303   \n9360   14.678727   5.145549  14.602763   5.135674  14.417904   5.125799   \n...          ...        ...        ...        ...        ...        ...   \n15551  12.107815  20.053227  12.276767  20.042757  12.216624  20.032052   \n27071  11.805642  21.544117  12.009963  21.532674  12.094039  21.521484   \n19871  11.689620  44.723135  11.834983  44.712698  11.875493  44.702122   \n7919   11.582731  27.587356  11.690385  27.574968  11.359487  27.562512   \n17711  11.887536  52.379312  12.029461  52.369158  12.159736  52.359020   \n\n        BidVol10     label  \n6624   14.358886  0.994064  \n19008  15.633435  1.023490  \n22608  14.802823  0.997709  \n22752  14.887010  0.988867  \n9360   14.103783  1.004776  \n...          ...       ...  \n15551  12.249340  1.002301  \n27071  12.267991  1.060175  \n19871  11.786179  0.985470  \n7919   11.151827  1.003915  \n17711  12.214726  0.967836  \n\n[37152 rows x 53 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>tic</th>\n      <th>close</th>\n      <th>last</th>\n      <th>volume</th>\n      <th>turnover</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>TotalNo</th>\n      <th>...</th>\n      <th>BidVol6</th>\n      <th>Bid7</th>\n      <th>BidVol7</th>\n      <th>Bid8</th>\n      <th>BidVol8</th>\n      <th>Bid9</th>\n      <th>BidVol9</th>\n      <th>Bid10</th>\n      <th>BidVol10</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6624</th>\n      <td>2023-06-01</td>\n      <td>600000.XSHG</td>\n      <td>7.275556</td>\n      <td>7.294183</td>\n      <td>19.623353</td>\n      <td>21.611260</td>\n      <td>7.33</td>\n      <td>7.347208</td>\n      <td>7.267917</td>\n      <td>4.449198</td>\n      <td>...</td>\n      <td>15.377164</td>\n      <td>7.138017</td>\n      <td>15.199319</td>\n      <td>7.128142</td>\n      <td>14.884772</td>\n      <td>7.118267</td>\n      <td>14.731421</td>\n      <td>7.108392</td>\n      <td>14.358886</td>\n      <td>0.994064</td>\n    </tr>\n    <tr>\n      <th>19008</th>\n      <td>2023-06-01</td>\n      <td>600008.XSHG</td>\n      <td>3.050000</td>\n      <td>3.063920</td>\n      <td>20.324832</td>\n      <td>21.443540</td>\n      <td>3.08</td>\n      <td>3.087250</td>\n      <td>3.040375</td>\n      <td>4.933034</td>\n      <td>...</td>\n      <td>16.838710</td>\n      <td>2.960492</td>\n      <td>16.670304</td>\n      <td>2.950615</td>\n      <td>16.292827</td>\n      <td>2.940738</td>\n      <td>15.983040</td>\n      <td>2.930861</td>\n      <td>15.633435</td>\n      <td>1.023490</td>\n    </tr>\n    <tr>\n      <th>22608</th>\n      <td>2023-06-01</td>\n      <td>600015.XSHG</td>\n      <td>5.730000</td>\n      <td>5.754824</td>\n      <td>19.498933</td>\n      <td>21.249332</td>\n      <td>5.77</td>\n      <td>5.806542</td>\n      <td>5.711750</td>\n      <td>4.427388</td>\n      <td>...</td>\n      <td>15.420127</td>\n      <td>5.618904</td>\n      <td>15.370532</td>\n      <td>5.609029</td>\n      <td>15.119865</td>\n      <td>5.599154</td>\n      <td>14.938520</td>\n      <td>5.589279</td>\n      <td>14.802823</td>\n      <td>0.997709</td>\n    </tr>\n    <tr>\n      <th>22752</th>\n      <td>2023-06-01</td>\n      <td>600017.XSHG</td>\n      <td>3.010000</td>\n      <td>3.008880</td>\n      <td>19.648348</td>\n      <td>20.747041</td>\n      <td>2.99</td>\n      <td>3.032292</td>\n      <td>2.961583</td>\n      <td>4.365749</td>\n      <td>...</td>\n      <td>16.327169</td>\n      <td>2.908928</td>\n      <td>16.151398</td>\n      <td>2.899053</td>\n      <td>15.610075</td>\n      <td>2.889178</td>\n      <td>15.203544</td>\n      <td>2.879303</td>\n      <td>14.887010</td>\n      <td>0.988867</td>\n    </tr>\n    <tr>\n      <th>9360</th>\n      <td>2023-06-01</td>\n      <td>600018.XSHG</td>\n      <td>5.260000</td>\n      <td>5.285801</td>\n      <td>18.915014</td>\n      <td>20.580564</td>\n      <td>5.28</td>\n      <td>5.309917</td>\n      <td>5.269542</td>\n      <td>4.288460</td>\n      <td>...</td>\n      <td>14.963574</td>\n      <td>5.155424</td>\n      <td>14.678727</td>\n      <td>5.145549</td>\n      <td>14.602763</td>\n      <td>5.135674</td>\n      <td>14.417904</td>\n      <td>5.125799</td>\n      <td>14.103783</td>\n      <td>1.004776</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15551</th>\n      <td>2023-12-29</td>\n      <td>688728.XSHG</td>\n      <td>20.477000</td>\n      <td>20.391906</td>\n      <td>18.222323</td>\n      <td>21.237417</td>\n      <td>20.65</td>\n      <td>20.690000</td>\n      <td>20.181583</td>\n      <td>4.068172</td>\n      <td>...</td>\n      <td>11.859839</td>\n      <td>20.063560</td>\n      <td>12.107815</td>\n      <td>20.053227</td>\n      <td>12.276767</td>\n      <td>20.042757</td>\n      <td>12.216624</td>\n      <td>20.032052</td>\n      <td>12.249340</td>\n      <td>1.002301</td>\n    </tr>\n    <tr>\n      <th>27071</th>\n      <td>2023-12-29</td>\n      <td>688772.XSHG</td>\n      <td>22.010556</td>\n      <td>21.908441</td>\n      <td>18.629867</td>\n      <td>21.713466</td>\n      <td>21.75</td>\n      <td>22.029250</td>\n      <td>21.511042</td>\n      <td>4.173233</td>\n      <td>...</td>\n      <td>11.793579</td>\n      <td>21.555735</td>\n      <td>11.805642</td>\n      <td>21.544117</td>\n      <td>12.009963</td>\n      <td>21.532674</td>\n      <td>12.094039</td>\n      <td>21.521484</td>\n      <td>12.267991</td>\n      <td>1.060175</td>\n    </tr>\n    <tr>\n      <th>19871</th>\n      <td>2023-12-29</td>\n      <td>688777.XSHG</td>\n      <td>45.341000</td>\n      <td>45.372965</td>\n      <td>18.358121</td>\n      <td>22.172390</td>\n      <td>45.30</td>\n      <td>45.671167</td>\n      <td>45.052417</td>\n      <td>4.062596</td>\n      <td>...</td>\n      <td>11.647429</td>\n      <td>44.733479</td>\n      <td>11.689620</td>\n      <td>44.723135</td>\n      <td>11.834983</td>\n      <td>44.712698</td>\n      <td>11.875493</td>\n      <td>44.702122</td>\n      <td>11.786179</td>\n      <td>0.985470</td>\n    </tr>\n    <tr>\n      <th>7919</th>\n      <td>2023-12-29</td>\n      <td>688819.XSHG</td>\n      <td>27.920000</td>\n      <td>28.023930</td>\n      <td>17.149986</td>\n      <td>20.484693</td>\n      <td>28.00</td>\n      <td>28.247083</td>\n      <td>27.862750</td>\n      <td>3.259858</td>\n      <td>...</td>\n      <td>11.430077</td>\n      <td>27.599237</td>\n      <td>11.582731</td>\n      <td>27.587356</td>\n      <td>11.690385</td>\n      <td>27.574968</td>\n      <td>11.359487</td>\n      <td>27.562512</td>\n      <td>11.151827</td>\n      <td>1.003915</td>\n    </tr>\n    <tr>\n      <th>17711</th>\n      <td>2023-12-29</td>\n      <td>688981.XSHG</td>\n      <td>53.020000</td>\n      <td>53.125762</td>\n      <td>18.828473</td>\n      <td>22.801503</td>\n      <td>53.00</td>\n      <td>53.500000</td>\n      <td>52.889250</td>\n      <td>4.656972</td>\n      <td>...</td>\n      <td>11.816843</td>\n      <td>52.389493</td>\n      <td>11.887536</td>\n      <td>52.379312</td>\n      <td>12.029461</td>\n      <td>52.369158</td>\n      <td>12.159736</td>\n      <td>52.359020</td>\n      <td>12.214726</td>\n      <td>0.967836</td>\n    </tr>\n  </tbody>\n</table>\n<p>37152 rows × 53 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T09:25:37.160291Z",
     "start_time": "2024-02-26T09:25:37.113346600Z"
    }
   },
   "id": "502c99431d26a813",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array(['2023-06-01', '2023-06-02', '2023-06-05', '2023-06-06',\n       '2023-06-07', '2023-06-08', '2023-06-09', '2023-06-12',\n       '2023-06-13', '2023-06-14', '2023-06-15', '2023-06-16',\n       '2023-06-19', '2023-06-20', '2023-06-21', '2023-06-26',\n       '2023-06-27', '2023-06-28', '2023-06-29', '2023-06-30',\n       '2023-07-03', '2023-07-04', '2023-07-05', '2023-07-06',\n       '2023-07-07', '2023-07-10', '2023-07-11', '2023-07-12',\n       '2023-07-13', '2023-07-14', '2023-07-17', '2023-07-18',\n       '2023-07-19', '2023-07-20', '2023-07-21', '2023-07-24',\n       '2023-07-25', '2023-07-26', '2023-07-27', '2023-07-28',\n       '2023-07-31', '2023-08-01', '2023-08-02', '2023-08-03',\n       '2023-08-04', '2023-08-07', '2023-08-08', '2023-08-09',\n       '2023-08-10', '2023-08-11', '2023-08-14', '2023-08-15',\n       '2023-08-16', '2023-08-17', '2023-08-18', '2023-08-21',\n       '2023-08-22', '2023-08-23', '2023-08-24', '2023-08-25',\n       '2023-08-28', '2023-08-29', '2023-08-30', '2023-08-31',\n       '2023-09-01', '2023-09-04', '2023-09-05', '2023-09-06',\n       '2023-09-07', '2023-09-08', '2023-09-11', '2023-09-12',\n       '2023-09-13', '2023-09-14', '2023-09-15', '2023-09-18',\n       '2023-09-19', '2023-09-20', '2023-09-21', '2023-09-22',\n       '2023-09-25', '2023-09-26', '2023-09-27', '2023-09-28',\n       '2023-10-09', '2023-10-10', '2023-10-11', '2023-10-12',\n       '2023-10-13', '2023-10-16', '2023-10-17', '2023-10-18',\n       '2023-10-19', '2023-10-20', '2023-10-23', '2023-10-24',\n       '2023-10-25', '2023-10-26', '2023-10-27', '2023-10-30',\n       '2023-10-31', '2023-11-01', '2023-11-02', '2023-11-03',\n       '2023-11-06', '2023-11-07', '2023-11-08', '2023-11-09',\n       '2023-11-10', '2023-11-13', '2023-11-14', '2023-11-15',\n       '2023-11-16', '2023-11-17', '2023-11-20', '2023-11-21',\n       '2023-11-22', '2023-11-23', '2023-11-24', '2023-11-27',\n       '2023-11-28', '2023-11-29', '2023-11-30', '2023-12-01',\n       '2023-12-04', '2023-12-05', '2023-12-06', '2023-12-07',\n       '2023-12-08', '2023-12-11', '2023-12-12', '2023-12-13',\n       '2023-12-14', '2023-12-15', '2023-12-18', '2023-12-19',\n       '2023-12-20', '2023-12-21', '2023-12-22', '2023-12-25',\n       '2023-12-26', '2023-12-27', '2023-12-28', '2023-12-29'],\n      dtype=object)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['date'].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T09:25:37.183955400Z",
     "start_time": "2024-02-26T09:25:37.163292100Z"
    }
   },
   "id": "9f453254f322a915",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "Successfully added turbulence index\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    tech_indicator_list = INDICATORS,\n",
    "                    use_vix=False,\n",
    "                    use_turbulence=True,\n",
    "                    user_defined_feature = False)\n",
    "\n",
    "processed = fe.preprocess_data(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T09:26:06.375445200Z",
     "start_time": "2024-02-26T09:25:37.175786800Z"
    }
   },
   "id": "4241ec645a93ff93",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "list_ticker = processed[\"tic\"].unique().tolist()\n",
    "list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "processed_full = processed_full.fillna(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T09:26:06.496537700Z",
     "start_time": "2024-02-26T09:26:06.380446Z"
    }
   },
   "id": "8cae4b4799dba1b6",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "             date          tic      close       last     volume   turnover  \\\n0      2023-06-01  600000.XSHG   7.275556   7.294183  19.623353  21.611260   \n1      2023-06-01  600008.XSHG   3.050000   3.063920  20.324832  21.443540   \n2      2023-06-01  600015.XSHG   5.730000   5.754824  19.498933  21.249332   \n3      2023-06-01  600017.XSHG   3.010000   3.008880  19.648348  20.747041   \n4      2023-06-01  600018.XSHG   5.260000   5.285801  18.915014  20.580564   \n...           ...          ...        ...        ...        ...        ...   \n54691  2023-12-29  688728.XSHG  20.477000  20.391906  18.222323  21.237417   \n54692  2023-12-29  688772.XSHG  22.010556  21.908441  18.629867  21.713466   \n54693  2023-12-29  688777.XSHG  45.341000  45.372965  18.358121  22.172390   \n54694  2023-12-29  688819.XSHG  27.920000  28.023930  17.149986  20.484693   \n54695  2023-12-29  688981.XSHG  53.020000  53.125762  18.828473  22.801503   \n\n        open       high        low   TotalNo  ...     label      macd  \\\n0       7.33   7.347208   7.267917  4.449198  ...  0.994064  0.000000   \n1       3.08   3.087250   3.040375  4.933034  ...  1.023490  0.000000   \n2       5.77   5.806542   5.711750  4.427388  ...  0.997709  0.000000   \n3       2.99   3.032292   2.961583  4.365749  ...  0.988867  0.000000   \n4       5.28   5.309917   5.269542  4.288460  ...  1.004776  0.000000   \n...      ...        ...        ...       ...  ...       ...       ...   \n54691  20.65  20.690000  20.181583  4.068172  ...  1.002301  0.204226   \n54692  21.75  22.029250  21.511042  4.173233  ...  1.060175  0.215572   \n54693  45.30  45.671167  45.052417  4.062596  ...  0.985470  0.462934   \n54694  28.00  28.247083  27.862750  3.259858  ...  1.003915 -0.763265   \n54695  53.00  53.500000  52.889250  4.656972  ...  0.967836 -0.297324   \n\n         boll_ub    boll_lb      rsi_30      cci_30       dx_30  close_30_sma  \\\n0       7.418058   7.207497  100.000000   66.666667  100.000000      7.275556   \n1       7.418058   7.207497  100.000000   66.666667  100.000000      3.050000   \n2       7.418058   7.207497  100.000000   66.666667  100.000000      5.730000   \n3       7.418058   7.207497  100.000000   66.666667  100.000000      3.010000   \n4       7.418058   7.207497  100.000000   66.666667  100.000000      5.260000   \n...          ...        ...         ...         ...         ...           ...   \n54691  21.668151  19.482275   57.103861    7.154112   10.923447     20.390377   \n54692  21.825375  20.245451   57.174715  210.385022   23.343688     20.955859   \n54693  48.089362  41.744701   49.473144   55.558650    8.488809     44.128232   \n54694  29.290833  26.843323   38.601587  -55.667253   21.686831     28.881818   \n54695  55.146308  51.437916   48.536028  -31.899498   11.724561     53.473125   \n\n       close_60_sma  turbulence  \n0          7.275556    0.000000  \n1          3.050000    0.000000  \n2          5.730000    0.000000  \n3          3.010000    0.000000  \n4          5.260000    0.000000  \n...             ...         ...  \n54691     19.067708    5.055898  \n54692     20.232331    5.055898  \n54693     43.651691    5.055898  \n54694     30.739834    5.055898  \n54695     54.428788    5.055898  \n\n[37152 rows x 62 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>tic</th>\n      <th>close</th>\n      <th>last</th>\n      <th>volume</th>\n      <th>turnover</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>TotalNo</th>\n      <th>...</th>\n      <th>label</th>\n      <th>macd</th>\n      <th>boll_ub</th>\n      <th>boll_lb</th>\n      <th>rsi_30</th>\n      <th>cci_30</th>\n      <th>dx_30</th>\n      <th>close_30_sma</th>\n      <th>close_60_sma</th>\n      <th>turbulence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2023-06-01</td>\n      <td>600000.XSHG</td>\n      <td>7.275556</td>\n      <td>7.294183</td>\n      <td>19.623353</td>\n      <td>21.611260</td>\n      <td>7.33</td>\n      <td>7.347208</td>\n      <td>7.267917</td>\n      <td>4.449198</td>\n      <td>...</td>\n      <td>0.994064</td>\n      <td>0.000000</td>\n      <td>7.418058</td>\n      <td>7.207497</td>\n      <td>100.000000</td>\n      <td>66.666667</td>\n      <td>100.000000</td>\n      <td>7.275556</td>\n      <td>7.275556</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2023-06-01</td>\n      <td>600008.XSHG</td>\n      <td>3.050000</td>\n      <td>3.063920</td>\n      <td>20.324832</td>\n      <td>21.443540</td>\n      <td>3.08</td>\n      <td>3.087250</td>\n      <td>3.040375</td>\n      <td>4.933034</td>\n      <td>...</td>\n      <td>1.023490</td>\n      <td>0.000000</td>\n      <td>7.418058</td>\n      <td>7.207497</td>\n      <td>100.000000</td>\n      <td>66.666667</td>\n      <td>100.000000</td>\n      <td>3.050000</td>\n      <td>3.050000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2023-06-01</td>\n      <td>600015.XSHG</td>\n      <td>5.730000</td>\n      <td>5.754824</td>\n      <td>19.498933</td>\n      <td>21.249332</td>\n      <td>5.77</td>\n      <td>5.806542</td>\n      <td>5.711750</td>\n      <td>4.427388</td>\n      <td>...</td>\n      <td>0.997709</td>\n      <td>0.000000</td>\n      <td>7.418058</td>\n      <td>7.207497</td>\n      <td>100.000000</td>\n      <td>66.666667</td>\n      <td>100.000000</td>\n      <td>5.730000</td>\n      <td>5.730000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2023-06-01</td>\n      <td>600017.XSHG</td>\n      <td>3.010000</td>\n      <td>3.008880</td>\n      <td>19.648348</td>\n      <td>20.747041</td>\n      <td>2.99</td>\n      <td>3.032292</td>\n      <td>2.961583</td>\n      <td>4.365749</td>\n      <td>...</td>\n      <td>0.988867</td>\n      <td>0.000000</td>\n      <td>7.418058</td>\n      <td>7.207497</td>\n      <td>100.000000</td>\n      <td>66.666667</td>\n      <td>100.000000</td>\n      <td>3.010000</td>\n      <td>3.010000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2023-06-01</td>\n      <td>600018.XSHG</td>\n      <td>5.260000</td>\n      <td>5.285801</td>\n      <td>18.915014</td>\n      <td>20.580564</td>\n      <td>5.28</td>\n      <td>5.309917</td>\n      <td>5.269542</td>\n      <td>4.288460</td>\n      <td>...</td>\n      <td>1.004776</td>\n      <td>0.000000</td>\n      <td>7.418058</td>\n      <td>7.207497</td>\n      <td>100.000000</td>\n      <td>66.666667</td>\n      <td>100.000000</td>\n      <td>5.260000</td>\n      <td>5.260000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>54691</th>\n      <td>2023-12-29</td>\n      <td>688728.XSHG</td>\n      <td>20.477000</td>\n      <td>20.391906</td>\n      <td>18.222323</td>\n      <td>21.237417</td>\n      <td>20.65</td>\n      <td>20.690000</td>\n      <td>20.181583</td>\n      <td>4.068172</td>\n      <td>...</td>\n      <td>1.002301</td>\n      <td>0.204226</td>\n      <td>21.668151</td>\n      <td>19.482275</td>\n      <td>57.103861</td>\n      <td>7.154112</td>\n      <td>10.923447</td>\n      <td>20.390377</td>\n      <td>19.067708</td>\n      <td>5.055898</td>\n    </tr>\n    <tr>\n      <th>54692</th>\n      <td>2023-12-29</td>\n      <td>688772.XSHG</td>\n      <td>22.010556</td>\n      <td>21.908441</td>\n      <td>18.629867</td>\n      <td>21.713466</td>\n      <td>21.75</td>\n      <td>22.029250</td>\n      <td>21.511042</td>\n      <td>4.173233</td>\n      <td>...</td>\n      <td>1.060175</td>\n      <td>0.215572</td>\n      <td>21.825375</td>\n      <td>20.245451</td>\n      <td>57.174715</td>\n      <td>210.385022</td>\n      <td>23.343688</td>\n      <td>20.955859</td>\n      <td>20.232331</td>\n      <td>5.055898</td>\n    </tr>\n    <tr>\n      <th>54693</th>\n      <td>2023-12-29</td>\n      <td>688777.XSHG</td>\n      <td>45.341000</td>\n      <td>45.372965</td>\n      <td>18.358121</td>\n      <td>22.172390</td>\n      <td>45.30</td>\n      <td>45.671167</td>\n      <td>45.052417</td>\n      <td>4.062596</td>\n      <td>...</td>\n      <td>0.985470</td>\n      <td>0.462934</td>\n      <td>48.089362</td>\n      <td>41.744701</td>\n      <td>49.473144</td>\n      <td>55.558650</td>\n      <td>8.488809</td>\n      <td>44.128232</td>\n      <td>43.651691</td>\n      <td>5.055898</td>\n    </tr>\n    <tr>\n      <th>54694</th>\n      <td>2023-12-29</td>\n      <td>688819.XSHG</td>\n      <td>27.920000</td>\n      <td>28.023930</td>\n      <td>17.149986</td>\n      <td>20.484693</td>\n      <td>28.00</td>\n      <td>28.247083</td>\n      <td>27.862750</td>\n      <td>3.259858</td>\n      <td>...</td>\n      <td>1.003915</td>\n      <td>-0.763265</td>\n      <td>29.290833</td>\n      <td>26.843323</td>\n      <td>38.601587</td>\n      <td>-55.667253</td>\n      <td>21.686831</td>\n      <td>28.881818</td>\n      <td>30.739834</td>\n      <td>5.055898</td>\n    </tr>\n    <tr>\n      <th>54695</th>\n      <td>2023-12-29</td>\n      <td>688981.XSHG</td>\n      <td>53.020000</td>\n      <td>53.125762</td>\n      <td>18.828473</td>\n      <td>22.801503</td>\n      <td>53.00</td>\n      <td>53.500000</td>\n      <td>52.889250</td>\n      <td>4.656972</td>\n      <td>...</td>\n      <td>0.967836</td>\n      <td>-0.297324</td>\n      <td>55.146308</td>\n      <td>51.437916</td>\n      <td>48.536028</td>\n      <td>-31.899498</td>\n      <td>11.724561</td>\n      <td>53.473125</td>\n      <td>54.428788</td>\n      <td>5.055898</td>\n    </tr>\n  </tbody>\n</table>\n<p>37152 rows × 62 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T09:26:06.550861200Z",
     "start_time": "2024-02-26T09:26:06.483799600Z"
    }
   },
   "id": "4e9eb4938186ef74",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# processed_full.to_csv('DRL/ZZ500_processed_full.csv', index=None)\n",
    "# processed_full = pd.read_csv('DRL/ZZ500_processed_full.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T09:26:06.576531Z",
     "start_time": "2024-02-26T09:26:06.535841500Z"
    }
   },
   "id": "67ae674a27cd41dc",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# processed_full"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T09:26:06.649414500Z",
     "start_time": "2024-02-26T09:26:06.546842500Z"
    }
   },
   "id": "dcb38c365982b5c",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\nTRAIN_START_DATE = '2018-01-03'\\nTRAIN_END_DATE = '2022-12-31'\\nTRADE_START_DATE = '2023-01-03'\\nTRADE_END_DATE = '2023-12-31'\\n\""
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_START_DATE = '2023-06-01'\n",
    "TRAIN_END_DATE = '2023-09-30'\n",
    "TRADE_START_DATE = '2023-10-09'\n",
    "TRADE_END_DATE = '2023-12-31'\n",
    "'''\n",
    "TRAIN_START_DATE = '2018-01-03'\n",
    "TRAIN_END_DATE = '2022-12-31'\n",
    "TRADE_START_DATE = '2023-01-03'\n",
    "TRADE_END_DATE = '2023-12-31'\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T09:26:06.675954200Z",
     "start_time": "2024-02-26T09:26:06.563429100Z"
    }
   },
   "id": "b8ed2ba359c3e951",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21672\n",
      "15480\n"
     ]
    }
   ],
   "source": [
    "train = data_split(processed_full, TRAIN_START_DATE,TRAIN_END_DATE)\n",
    "trade = data_split(processed_full, TRADE_START_DATE,TRADE_END_DATE)\n",
    "train_length = len(train)\n",
    "trade_length = len(trade)\n",
    "print(train_length)\n",
    "print(trade_length)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T09:26:06.705690800Z",
     "start_time": "2024-02-26T09:26:06.580086900Z"
    }
   },
   "id": "b9d621dc1bf026b5",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 258, State Space: 2581\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + 2 * stock_dimension + len(INDICATORS) * stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T09:26:06.707758300Z",
     "start_time": "2024-02-26T09:26:06.628058Z"
    }
   },
   "id": "ef4717733824536b",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4\n",
    "}\n",
    "\n",
    "\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T09:26:06.800067Z",
     "start_time": "2024-02-26T09:26:06.642413600Z"
    }
   },
   "id": "59852ec8c9b83058",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T09:26:06.829132Z",
     "start_time": "2024-02-26T09:26:06.657416Z"
    }
   },
   "id": "e48decd55ec1e90",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if_using_a2c = True\n",
    "if_using_ddpg = True\n",
    "if_using_ppo = True\n",
    "if_using_td3 = True\n",
    "if_using_sac = True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T09:26:06.904886400Z",
     "start_time": "2024-02-26T09:26:06.687342900Z"
    }
   },
   "id": "753a35936e486ea8",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to results/a2c\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_a2c = agent.get_model(\"a2c\")\n",
    "\n",
    "if if_using_a2c:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/a2c'\n",
    "  new_logger_a2c = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_a2c.set_logger(new_logger_a2c)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T09:26:12.515302200Z",
     "start_time": "2024-02-26T09:26:06.701633Z"
    }
   },
   "id": "89a0b53fc8d798f6",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 80          |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 6           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -368        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | -133        |\n",
      "|    reward             | -0.30347243 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 0.568       |\n",
      "---------------------------------------\n",
      "day: 83, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 934133.48\n",
      "total_reward: -65866.52\n",
      "total_cost: 15929.67\n",
      "total_trades: 15467\n",
      "Sharpe: -1.399\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 95          |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 10          |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -368        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | 277         |\n",
      "|    reward             | -0.20289713 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 1.45        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 99         |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 15         |\n",
      "|    total_timesteps    | 1500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -368       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | -172       |\n",
      "|    reward             | -0.7018349 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.296      |\n",
      "--------------------------------------\n",
      "day: 83, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 836242.19\n",
      "total_reward: -163757.81\n",
      "total_cost: 11036.61\n",
      "total_trades: 14233\n",
      "Sharpe: -3.452\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 101        |\n",
      "|    iterations         | 400        |\n",
      "|    time_elapsed       | 19         |\n",
      "|    total_timesteps    | 2000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -369       |\n",
      "|    explained_variance | 0.0447     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 399        |\n",
      "|    policy_loss        | 604        |\n",
      "|    reward             | -1.9487246 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 3.84       |\n",
      "--------------------------------------\n",
      "day: 83, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 907128.63\n",
      "total_reward: -92871.37\n",
      "total_cost: 9678.28\n",
      "total_trades: 13851\n",
      "Sharpe: -1.211\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 24         |\n",
      "|    total_timesteps    | 2500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -369       |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 499        |\n",
      "|    policy_loss        | -537       |\n",
      "|    reward             | 0.26113677 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 2.59       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 104        |\n",
      "|    iterations         | 600        |\n",
      "|    time_elapsed       | 28         |\n",
      "|    total_timesteps    | 3000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -369       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 599        |\n",
      "|    policy_loss        | -712       |\n",
      "|    reward             | 0.35741553 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 4.27       |\n",
      "--------------------------------------\n",
      "day: 83, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 878806.30\n",
      "total_reward: -121193.70\n",
      "total_cost: 8853.45\n",
      "total_trades: 13858\n",
      "Sharpe: -2.657\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 106        |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 32         |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -370       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 699        |\n",
      "|    policy_loss        | -710       |\n",
      "|    reward             | 0.64686424 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 4.9        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 107         |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 37          |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -370        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | -138        |\n",
      "|    reward             | -0.93831617 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 0.2         |\n",
      "---------------------------------------\n",
      "day: 83, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 931085.11\n",
      "total_reward: -68914.89\n",
      "total_cost: 14295.91\n",
      "total_trades: 15130\n",
      "Sharpe: -1.646\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 107        |\n",
      "|    iterations         | 900        |\n",
      "|    time_elapsed       | 41         |\n",
      "|    total_timesteps    | 4500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -370       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 899        |\n",
      "|    policy_loss        | 627        |\n",
      "|    reward             | 0.71041167 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 3.3        |\n",
      "--------------------------------------\n",
      "day: 83, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 880793.93\n",
      "total_reward: -119206.07\n",
      "total_cost: 11412.90\n",
      "total_trades: 14443\n",
      "Sharpe: -2.765\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 108        |\n",
      "|    iterations         | 1000       |\n",
      "|    time_elapsed       | 46         |\n",
      "|    total_timesteps    | 5000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -371       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 999        |\n",
      "|    policy_loss        | 822        |\n",
      "|    reward             | 0.31665975 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 5.96       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 108        |\n",
      "|    iterations         | 1100       |\n",
      "|    time_elapsed       | 50         |\n",
      "|    total_timesteps    | 5500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -371       |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1099       |\n",
      "|    policy_loss        | -259       |\n",
      "|    reward             | 0.32473555 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 0.655      |\n",
      "--------------------------------------\n",
      "day: 83, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 947637.37\n",
      "total_reward: -52362.63\n",
      "total_cost: 8171.85\n",
      "total_trades: 13655\n",
      "Sharpe: -1.173\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 55        |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -371      |\n",
      "|    explained_variance | -0.000323 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | -263      |\n",
      "|    reward             | 1.9220042 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.849     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 109         |\n",
      "|    iterations         | 1300        |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 6500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -372        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1299        |\n",
      "|    policy_loss        | -80.4       |\n",
      "|    reward             | -0.46794853 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 0.124       |\n",
      "---------------------------------------\n",
      "day: 83, episode: 80\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 957242.97\n",
      "total_reward: -42757.03\n",
      "total_cost: 9009.34\n",
      "total_trades: 13208\n",
      "Sharpe: -0.961\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 109       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 64        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -372      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | -53       |\n",
      "|    reward             | 2.2867525 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.636     |\n",
      "-------------------------------------\n",
      "day: 83, episode: 90\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 973159.02\n",
      "total_reward: -26840.98\n",
      "total_cost: 7780.06\n",
      "total_trades: 12273\n",
      "Sharpe: -0.484\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 109         |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -372        |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1499        |\n",
      "|    policy_loss        | 197         |\n",
      "|    reward             | -0.18844071 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.658       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 109       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 72        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -373      |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | -929      |\n",
      "|    reward             | 1.3973713 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 6.55      |\n",
      "-------------------------------------\n",
      "day: 83, episode: 100\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 958770.28\n",
      "total_reward: -41229.72\n",
      "total_cost: 5907.83\n",
      "total_trades: 11669\n",
      "Sharpe: -0.841\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 109        |\n",
      "|    iterations         | 1700       |\n",
      "|    time_elapsed       | 77         |\n",
      "|    total_timesteps    | 8500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -373       |\n",
      "|    explained_variance | 0.205      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1699       |\n",
      "|    policy_loss        | 152        |\n",
      "|    reward             | 0.30605283 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 0.294      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 110         |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -373        |\n",
      "|    explained_variance | 0.246       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1799        |\n",
      "|    policy_loss        | 6.42        |\n",
      "|    reward             | 0.110313974 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.858       |\n",
      "---------------------------------------\n",
      "day: 83, episode: 110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 900556.10\n",
      "total_reward: -99443.90\n",
      "total_cost: 3978.27\n",
      "total_trades: 10918\n",
      "Sharpe: -2.080\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 110        |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 85         |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -373       |\n",
      "|    explained_variance | -0.102     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | 730        |\n",
      "|    reward             | 0.20399645 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 24.4       |\n",
      "--------------------------------------\n",
      "day: 83, episode: 120\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 925949.32\n",
      "total_reward: -74050.68\n",
      "total_cost: 4052.93\n",
      "total_trades: 10895\n",
      "Sharpe: -1.664\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 110         |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 90          |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -374        |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | -73.4       |\n",
      "|    reward             | -0.64493454 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.148       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 111         |\n",
      "|    iterations         | 2100        |\n",
      "|    time_elapsed       | 94          |\n",
      "|    total_timesteps    | 10500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -374        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2099        |\n",
      "|    policy_loss        | -52.1       |\n",
      "|    reward             | -0.35171092 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.504       |\n",
      "---------------------------------------\n",
      "day: 83, episode: 130\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 896090.21\n",
      "total_reward: -103909.79\n",
      "total_cost: 3990.87\n",
      "total_trades: 10854\n",
      "Sharpe: -2.449\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 111        |\n",
      "|    iterations         | 2200       |\n",
      "|    time_elapsed       | 98         |\n",
      "|    total_timesteps    | 11000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -374       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2199       |\n",
      "|    policy_loss        | -223       |\n",
      "|    reward             | -0.4571548 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 0.772      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 111          |\n",
      "|    iterations         | 2300         |\n",
      "|    time_elapsed       | 103          |\n",
      "|    total_timesteps    | 11500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -374         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2299         |\n",
      "|    policy_loss        | -1.85        |\n",
      "|    reward             | -0.057149664 |\n",
      "|    std                | 1.03         |\n",
      "|    value_loss         | 0.518        |\n",
      "----------------------------------------\n",
      "day: 83, episode: 140\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 909981.36\n",
      "total_reward: -90018.64\n",
      "total_cost: 3571.59\n",
      "total_trades: 11214\n",
      "Sharpe: -2.013\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 111         |\n",
      "|    iterations         | 2400        |\n",
      "|    time_elapsed       | 107         |\n",
      "|    total_timesteps    | 12000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -374        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2399        |\n",
      "|    policy_loss        | -8.55       |\n",
      "|    reward             | -0.71102524 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.206       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 111        |\n",
      "|    iterations         | 2500       |\n",
      "|    time_elapsed       | 112        |\n",
      "|    total_timesteps    | 12500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -375       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2499       |\n",
      "|    policy_loss        | 602        |\n",
      "|    reward             | -1.4529022 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 4.19       |\n",
      "--------------------------------------\n",
      "day: 83, episode: 150\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 928419.75\n",
      "total_reward: -71580.25\n",
      "total_cost: 2885.59\n",
      "total_trades: 10918\n",
      "Sharpe: -1.644\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 116       |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -375      |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | -46       |\n",
      "|    reward             | 0.4768548 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.587     |\n",
      "-------------------------------------\n",
      "day: 83, episode: 160\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 907269.99\n",
      "total_reward: -92730.01\n",
      "total_cost: 2757.29\n",
      "total_trades: 10698\n",
      "Sharpe: -1.828\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 111        |\n",
      "|    iterations         | 2700       |\n",
      "|    time_elapsed       | 121        |\n",
      "|    total_timesteps    | 13500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -375       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2699       |\n",
      "|    policy_loss        | -533       |\n",
      "|    reward             | 0.43266556 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 2.39       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 111          |\n",
      "|    iterations         | 2800         |\n",
      "|    time_elapsed       | 125          |\n",
      "|    total_timesteps    | 14000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -375         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2799         |\n",
      "|    policy_loss        | -450         |\n",
      "|    reward             | 0.0040465915 |\n",
      "|    std                | 1.04         |\n",
      "|    value_loss         | 2.21         |\n",
      "----------------------------------------\n",
      "day: 83, episode: 170\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 899825.59\n",
      "total_reward: -100174.41\n",
      "total_cost: 2770.76\n",
      "total_trades: 10469\n",
      "Sharpe: -1.858\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 111        |\n",
      "|    iterations         | 2900       |\n",
      "|    time_elapsed       | 129        |\n",
      "|    total_timesteps    | 14500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -376       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2899       |\n",
      "|    policy_loss        | -120       |\n",
      "|    reward             | -1.0866692 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 0.263      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 134       |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -376      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | 434       |\n",
      "|    reward             | 0.6844392 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 1.93      |\n",
      "-------------------------------------\n",
      "day: 83, episode: 180\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 940095.41\n",
      "total_reward: -59904.59\n",
      "total_cost: 2814.26\n",
      "total_trades: 10332\n",
      "Sharpe: -1.154\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 111        |\n",
      "|    iterations         | 3100       |\n",
      "|    time_elapsed       | 138        |\n",
      "|    total_timesteps    | 15500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -377       |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3099       |\n",
      "|    policy_loss        | 920        |\n",
      "|    reward             | 0.21938656 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 6.85       |\n",
      "--------------------------------------\n",
      "day: 83, episode: 190\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 901860.62\n",
      "total_reward: -98139.38\n",
      "total_cost: 2375.14\n",
      "total_trades: 9802\n",
      "Sharpe: -1.773\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 111        |\n",
      "|    iterations         | 3200       |\n",
      "|    time_elapsed       | 143        |\n",
      "|    total_timesteps    | 16000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -377       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3199       |\n",
      "|    policy_loss        | -532       |\n",
      "|    reward             | 0.18176351 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 2.27       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 147       |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -377      |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | -107      |\n",
      "|    reward             | 2.1837656 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 0.279     |\n",
      "-------------------------------------\n",
      "day: 83, episode: 200\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 904984.09\n",
      "total_reward: -95015.91\n",
      "total_cost: 2995.82\n",
      "total_trades: 10035\n",
      "Sharpe: -1.772\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 111        |\n",
      "|    iterations         | 3400       |\n",
      "|    time_elapsed       | 152        |\n",
      "|    total_timesteps    | 17000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -378       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3399       |\n",
      "|    policy_loss        | -229       |\n",
      "|    reward             | 0.20314498 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 0.453      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 157       |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -378      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | 193       |\n",
      "|    reward             | 0.8829416 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 1.7       |\n",
      "-------------------------------------\n",
      "day: 83, episode: 210\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 951314.62\n",
      "total_reward: -48685.38\n",
      "total_cost: 2810.94\n",
      "total_trades: 10346\n",
      "Sharpe: -1.051\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 111         |\n",
      "|    iterations         | 3600        |\n",
      "|    time_elapsed       | 161         |\n",
      "|    total_timesteps    | 18000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -378        |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3599        |\n",
      "|    policy_loss        | -40.5       |\n",
      "|    reward             | -0.19194432 |\n",
      "|    std                | 1.05        |\n",
      "|    value_loss         | 0.617       |\n",
      "---------------------------------------\n",
      "day: 83, episode: 220\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1000264.34\n",
      "total_reward: 264.34\n",
      "total_cost: 3019.15\n",
      "total_trades: 10139\n",
      "Sharpe: 0.074\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 165       |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -379      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | -1.28e+03 |\n",
      "|    reward             | 1.5998644 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 12.1      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 111        |\n",
      "|    iterations         | 3800       |\n",
      "|    time_elapsed       | 170        |\n",
      "|    total_timesteps    | 19000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -379       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3799       |\n",
      "|    policy_loss        | 1.01e+03   |\n",
      "|    reward             | 0.09839965 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 8.4        |\n",
      "--------------------------------------\n",
      "day: 83, episode: 230\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 938750.13\n",
      "total_reward: -61249.87\n",
      "total_cost: 3122.35\n",
      "total_trades: 10154\n",
      "Sharpe: -1.299\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 111         |\n",
      "|    iterations         | 3900        |\n",
      "|    time_elapsed       | 174         |\n",
      "|    total_timesteps    | 19500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -379        |\n",
      "|    explained_variance | 0.524       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3899        |\n",
      "|    policy_loss        | 473         |\n",
      "|    reward             | -0.92420524 |\n",
      "|    std                | 1.05        |\n",
      "|    value_loss         | 1.89        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 111        |\n",
      "|    iterations         | 4000       |\n",
      "|    time_elapsed       | 178        |\n",
      "|    total_timesteps    | 20000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -380       |\n",
      "|    explained_variance | 0.738      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3999       |\n",
      "|    policy_loss        | 926        |\n",
      "|    reward             | 0.27887893 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 7.44       |\n",
      "--------------------------------------\n",
      "day: 83, episode: 240\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 998276.07\n",
      "total_reward: -1723.93\n",
      "total_cost: 2228.73\n",
      "total_trades: 10015\n",
      "Sharpe: 0.029\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 111        |\n",
      "|    iterations         | 4100       |\n",
      "|    time_elapsed       | 184        |\n",
      "|    total_timesteps    | 20500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -380       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4099       |\n",
      "|    policy_loss        | -47.4      |\n",
      "|    reward             | -1.0231459 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 0.228      |\n",
      "--------------------------------------\n",
      "day: 83, episode: 250\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 985187.83\n",
      "total_reward: -14812.17\n",
      "total_cost: 3311.90\n",
      "total_trades: 10278\n",
      "Sharpe: -0.258\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 111        |\n",
      "|    iterations         | 4200       |\n",
      "|    time_elapsed       | 188        |\n",
      "|    total_timesteps    | 21000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -380       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4199       |\n",
      "|    policy_loss        | 133        |\n",
      "|    reward             | 0.05851576 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 0.432      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 111        |\n",
      "|    iterations         | 4300       |\n",
      "|    time_elapsed       | 192        |\n",
      "|    total_timesteps    | 21500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -380       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4299       |\n",
      "|    policy_loss        | -157       |\n",
      "|    reward             | -0.3801799 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 0.528      |\n",
      "--------------------------------------\n",
      "day: 83, episode: 260\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 963436.46\n",
      "total_reward: -36563.54\n",
      "total_cost: 2841.78\n",
      "total_trades: 10560\n",
      "Sharpe: -0.804\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 4400      |\n",
      "|    time_elapsed       | 197       |\n",
      "|    total_timesteps    | 22000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -380      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4399      |\n",
      "|    policy_loss        | 167       |\n",
      "|    reward             | 0.1652785 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.471     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 111        |\n",
      "|    iterations         | 4500       |\n",
      "|    time_elapsed       | 201        |\n",
      "|    total_timesteps    | 22500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -381       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4499       |\n",
      "|    policy_loss        | -13.9      |\n",
      "|    reward             | -0.9058326 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 0.0986     |\n",
      "--------------------------------------\n",
      "day: 83, episode: 270\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 921540.82\n",
      "total_reward: -78459.18\n",
      "total_cost: 2717.82\n",
      "total_trades: 10476\n",
      "Sharpe: -1.813\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 111        |\n",
      "|    iterations         | 4600       |\n",
      "|    time_elapsed       | 205        |\n",
      "|    total_timesteps    | 23000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -381       |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4599       |\n",
      "|    policy_loss        | 248        |\n",
      "|    reward             | -1.2996484 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 2.23       |\n",
      "--------------------------------------\n",
      "day: 83, episode: 280\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 951751.64\n",
      "total_reward: -48248.36\n",
      "total_cost: 2378.96\n",
      "total_trades: 10185\n",
      "Sharpe: -1.110\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 111        |\n",
      "|    iterations         | 4700       |\n",
      "|    time_elapsed       | 209        |\n",
      "|    total_timesteps    | 23500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -381       |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4699       |\n",
      "|    policy_loss        | -217       |\n",
      "|    reward             | 0.13851468 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 0.763      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 112       |\n",
      "|    iterations         | 4800      |\n",
      "|    time_elapsed       | 214       |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -382      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4799      |\n",
      "|    policy_loss        | -501      |\n",
      "|    reward             | 1.4361403 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 1.91      |\n",
      "-------------------------------------\n",
      "day: 83, episode: 290\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 951844.05\n",
      "total_reward: -48155.95\n",
      "total_cost: 2716.14\n",
      "total_trades: 10379\n",
      "Sharpe: -1.106\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 112        |\n",
      "|    iterations         | 4900       |\n",
      "|    time_elapsed       | 218        |\n",
      "|    total_timesteps    | 24500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -382       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4899       |\n",
      "|    policy_loss        | -587       |\n",
      "|    reward             | 0.24477382 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 3.18       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 112         |\n",
      "|    iterations         | 5000        |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 25000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -382        |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4999        |\n",
      "|    policy_loss        | -231        |\n",
      "|    reward             | -0.47089925 |\n",
      "|    std                | 1.07        |\n",
      "|    value_loss         | 0.409       |\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                             tb_log_name='a2c',\n",
    "                             total_timesteps=25000) if if_using_a2c else None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T09:29:55.337998700Z",
     "start_time": "2024-02-26T09:26:12.514294300Z"
    }
   },
   "id": "1d4d91f26ebeab92",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to results/ddpg\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_ddpg = agent.get_model(\"ddpg\")\n",
    "\n",
    "if if_using_ddpg:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/ddpg'\n",
    "  new_logger_ddpg = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_ddpg.set_logger(new_logger_ddpg)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T09:29:55.425762300Z",
     "start_time": "2024-02-26T09:29:55.333998Z"
    }
   },
   "id": "820b31cc0a5d9ac0",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 83, episode: 300\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 885103.61\n",
      "total_reward: -114896.39\n",
      "total_cost: 21604.41\n",
      "total_trades: 18587\n",
      "Sharpe: -2.407\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 4          |\n",
      "|    fps             | 47         |\n",
      "|    time_elapsed    | 7          |\n",
      "|    total_timesteps | 336        |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 15.8       |\n",
      "|    critic_loss     | 64.1       |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 235        |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 8          |\n",
      "|    fps             | 41         |\n",
      "|    time_elapsed    | 16         |\n",
      "|    total_timesteps | 672        |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 13         |\n",
      "|    critic_loss     | 98.1       |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 571        |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 310\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 881387.31\n",
      "total_reward: -118612.69\n",
      "total_cost: 1007.71\n",
      "total_trades: 11205\n",
      "Sharpe: -2.324\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 12         |\n",
      "|    fps             | 39         |\n",
      "|    time_elapsed    | 25         |\n",
      "|    total_timesteps | 1008       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 12.5       |\n",
      "|    critic_loss     | 8.78       |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 907        |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 16         |\n",
      "|    fps             | 38         |\n",
      "|    time_elapsed    | 34         |\n",
      "|    total_timesteps | 1344       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 11.7       |\n",
      "|    critic_loss     | 2.89       |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 1243       |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 20         |\n",
      "|    fps             | 38         |\n",
      "|    time_elapsed    | 43         |\n",
      "|    total_timesteps | 1680       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 11.3       |\n",
      "|    critic_loss     | 5.24       |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 1579       |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 320\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 881387.31\n",
      "total_reward: -118612.69\n",
      "total_cost: 1007.71\n",
      "total_trades: 11205\n",
      "Sharpe: -2.324\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 24         |\n",
      "|    fps             | 37         |\n",
      "|    time_elapsed    | 53         |\n",
      "|    total_timesteps | 2016       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 12         |\n",
      "|    critic_loss     | 0.368      |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 1915       |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 28         |\n",
      "|    fps             | 37         |\n",
      "|    time_elapsed    | 63         |\n",
      "|    total_timesteps | 2352       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 11.4       |\n",
      "|    critic_loss     | 0.334      |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 2251       |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 330\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 881387.31\n",
      "total_reward: -118612.69\n",
      "total_cost: 1007.71\n",
      "total_trades: 11205\n",
      "Sharpe: -2.324\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 32         |\n",
      "|    fps             | 37         |\n",
      "|    time_elapsed    | 72         |\n",
      "|    total_timesteps | 2688       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 9.95       |\n",
      "|    critic_loss     | 7.71       |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 2587       |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 36         |\n",
      "|    fps             | 36         |\n",
      "|    time_elapsed    | 82         |\n",
      "|    total_timesteps | 3024       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 10.6       |\n",
      "|    critic_loss     | 0.606      |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 2923       |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 40         |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 93         |\n",
      "|    total_timesteps | 3360       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 11.6       |\n",
      "|    critic_loss     | 0.103      |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 3259       |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 340\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 881387.31\n",
      "total_reward: -118612.69\n",
      "total_cost: 1007.71\n",
      "total_trades: 11205\n",
      "Sharpe: -2.324\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 44         |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 103        |\n",
      "|    total_timesteps | 3696       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 20.2       |\n",
      "|    critic_loss     | 1.47e+03   |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 3595       |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 48         |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 112        |\n",
      "|    total_timesteps | 4032       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 10.4       |\n",
      "|    critic_loss     | 0.262      |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 3931       |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 350\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 881387.31\n",
      "total_reward: -118612.69\n",
      "total_cost: 1007.71\n",
      "total_trades: 11205\n",
      "Sharpe: -2.324\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 52         |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 122        |\n",
      "|    total_timesteps | 4368       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 9.43       |\n",
      "|    critic_loss     | 0.057      |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 4267       |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 56         |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 131        |\n",
      "|    total_timesteps | 4704       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 9.94       |\n",
      "|    critic_loss     | 0.092      |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 4603       |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 60         |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 141        |\n",
      "|    total_timesteps | 5040       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 8.12       |\n",
      "|    critic_loss     | 0.265      |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 4939       |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 360\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 881387.31\n",
      "total_reward: -118612.69\n",
      "total_cost: 1007.71\n",
      "total_trades: 11205\n",
      "Sharpe: -2.324\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 64         |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 150        |\n",
      "|    total_timesteps | 5376       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 8.65       |\n",
      "|    critic_loss     | 0.178      |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 5275       |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 68         |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 160        |\n",
      "|    total_timesteps | 5712       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 9.27       |\n",
      "|    critic_loss     | 0.294      |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 5611       |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 370\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 881387.31\n",
      "total_reward: -118612.69\n",
      "total_cost: 1007.71\n",
      "total_trades: 11205\n",
      "Sharpe: -2.324\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 72         |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 170        |\n",
      "|    total_timesteps | 6048       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 8.82       |\n",
      "|    critic_loss     | 0.00497    |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 5947       |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 76         |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 179        |\n",
      "|    total_timesteps | 6384       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 9.28       |\n",
      "|    critic_loss     | 0.0119     |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 6283       |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 80         |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 189        |\n",
      "|    total_timesteps | 6720       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 8.18       |\n",
      "|    critic_loss     | 1.25       |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 6619       |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 380\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 881387.31\n",
      "total_reward: -118612.69\n",
      "total_cost: 1007.71\n",
      "total_trades: 11205\n",
      "Sharpe: -2.324\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 84         |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 198        |\n",
      "|    total_timesteps | 7056       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 8.49       |\n",
      "|    critic_loss     | 0.0654     |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 6955       |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 88         |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 208        |\n",
      "|    total_timesteps | 7392       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 7.38       |\n",
      "|    critic_loss     | 1.03       |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 7291       |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 390\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 881387.31\n",
      "total_reward: -118612.69\n",
      "total_cost: 1007.71\n",
      "total_trades: 11205\n",
      "Sharpe: -2.324\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 92         |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 219        |\n",
      "|    total_timesteps | 7728       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 8.55       |\n",
      "|    critic_loss     | 0.796      |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 7627       |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 96         |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 229        |\n",
      "|    total_timesteps | 8064       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 8.19       |\n",
      "|    critic_loss     | 0.126      |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 7963       |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 100        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 238        |\n",
      "|    total_timesteps | 8400       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 7.48       |\n",
      "|    critic_loss     | 0.00239    |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 8299       |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 400\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 881387.31\n",
      "total_reward: -118612.69\n",
      "total_cost: 1007.71\n",
      "total_trades: 11205\n",
      "Sharpe: -2.324\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 104        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 248        |\n",
      "|    total_timesteps | 8736       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 7.16       |\n",
      "|    critic_loss     | 0.00404    |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 8635       |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 108        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 258        |\n",
      "|    total_timesteps | 9072       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 6.81       |\n",
      "|    critic_loss     | 0.0359     |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 8971       |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 410\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 881387.31\n",
      "total_reward: -118612.69\n",
      "total_cost: 1007.71\n",
      "total_trades: 11205\n",
      "Sharpe: -2.324\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 112        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 267        |\n",
      "|    total_timesteps | 9408       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 7.37       |\n",
      "|    critic_loss     | 0.023      |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 9307       |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 116        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 276        |\n",
      "|    total_timesteps | 9744       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 6.03       |\n",
      "|    critic_loss     | 0.0528     |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 9643       |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 120        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 285        |\n",
      "|    total_timesteps | 10080      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 5.89       |\n",
      "|    critic_loss     | 0.0293     |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 9979       |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 420\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 881387.31\n",
      "total_reward: -118612.69\n",
      "total_cost: 1007.71\n",
      "total_trades: 11205\n",
      "Sharpe: -2.324\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 124        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 294        |\n",
      "|    total_timesteps | 10416      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 6.15       |\n",
      "|    critic_loss     | 0.0139     |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 10315      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 128        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 303        |\n",
      "|    total_timesteps | 10752      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 6.18       |\n",
      "|    critic_loss     | 0.00716    |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 10651      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 430\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 881387.31\n",
      "total_reward: -118612.69\n",
      "total_cost: 1007.71\n",
      "total_trades: 11205\n",
      "Sharpe: -2.324\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 132        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 313        |\n",
      "|    total_timesteps | 11088      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 6.16       |\n",
      "|    critic_loss     | 0.00998    |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 10987      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 136        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 322        |\n",
      "|    total_timesteps | 11424      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 5.3        |\n",
      "|    critic_loss     | 0.0179     |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 11323      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 140        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 333        |\n",
      "|    total_timesteps | 11760      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 6.09       |\n",
      "|    critic_loss     | 0.0419     |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 11659      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 440\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 881387.31\n",
      "total_reward: -118612.69\n",
      "total_cost: 1007.71\n",
      "total_trades: 11205\n",
      "Sharpe: -2.324\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 144        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 342        |\n",
      "|    total_timesteps | 12096      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 4.48       |\n",
      "|    critic_loss     | 2.31       |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 11995      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 148        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 352        |\n",
      "|    total_timesteps | 12432      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 5.25       |\n",
      "|    critic_loss     | 0.0142     |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 12331      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 450\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 881387.31\n",
      "total_reward: -118612.69\n",
      "total_cost: 1007.71\n",
      "total_trades: 11205\n",
      "Sharpe: -2.324\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 152        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 361        |\n",
      "|    total_timesteps | 12768      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 5.57       |\n",
      "|    critic_loss     | 0.00445    |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 12667      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 156        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 370        |\n",
      "|    total_timesteps | 13104      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 5.55       |\n",
      "|    critic_loss     | 0.00243    |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 13003      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 160        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 379        |\n",
      "|    total_timesteps | 13440      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 4.52       |\n",
      "|    critic_loss     | 0.0142     |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 13339      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 460\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 881387.31\n",
      "total_reward: -118612.69\n",
      "total_cost: 1007.71\n",
      "total_trades: 11205\n",
      "Sharpe: -2.324\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 164        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 388        |\n",
      "|    total_timesteps | 13776      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 4.37       |\n",
      "|    critic_loss     | 0.00772    |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 13675      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 168        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 397        |\n",
      "|    total_timesteps | 14112      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 4.71       |\n",
      "|    critic_loss     | 0.0639     |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 14011      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 470\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 881387.31\n",
      "total_reward: -118612.69\n",
      "total_cost: 1007.71\n",
      "total_trades: 11205\n",
      "Sharpe: -2.324\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 172        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 406        |\n",
      "|    total_timesteps | 14448      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 4.58       |\n",
      "|    critic_loss     | 0.00524    |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 14347      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 176        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 415        |\n",
      "|    total_timesteps | 14784      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 4.97       |\n",
      "|    critic_loss     | 0.00509    |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 14683      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 180        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 424        |\n",
      "|    total_timesteps | 15120      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 4.01       |\n",
      "|    critic_loss     | 0.0126     |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 15019      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 480\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 881387.31\n",
      "total_reward: -118612.69\n",
      "total_cost: 1007.71\n",
      "total_trades: 11205\n",
      "Sharpe: -2.324\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 184        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 434        |\n",
      "|    total_timesteps | 15456      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 2.97       |\n",
      "|    critic_loss     | 0.00986    |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 15355      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 188        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 443        |\n",
      "|    total_timesteps | 15792      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 3.58       |\n",
      "|    critic_loss     | 0.00152    |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 15691      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 490\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 881387.31\n",
      "total_reward: -118612.69\n",
      "total_cost: 1007.71\n",
      "total_trades: 11205\n",
      "Sharpe: -2.324\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 192        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 452        |\n",
      "|    total_timesteps | 16128      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 4.2        |\n",
      "|    critic_loss     | 0.0054     |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 16027      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 196        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 461        |\n",
      "|    total_timesteps | 16464      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 2.95       |\n",
      "|    critic_loss     | 0.0214     |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 16363      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 200        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 470        |\n",
      "|    total_timesteps | 16800      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 3.53       |\n",
      "|    critic_loss     | 0.0132     |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 16699      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 500\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 881387.31\n",
      "total_reward: -118612.69\n",
      "total_cost: 1007.71\n",
      "total_trades: 11205\n",
      "Sharpe: -2.324\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 204        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 479        |\n",
      "|    total_timesteps | 17136      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 3.58       |\n",
      "|    critic_loss     | 0.00812    |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 17035      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 208        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 488        |\n",
      "|    total_timesteps | 17472      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 2.68       |\n",
      "|    critic_loss     | 0.0044     |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 17371      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 510\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 881387.31\n",
      "total_reward: -118612.69\n",
      "total_cost: 1007.71\n",
      "total_trades: 11205\n",
      "Sharpe: -2.324\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 212        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 497        |\n",
      "|    total_timesteps | 17808      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 3.04       |\n",
      "|    critic_loss     | 0.182      |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 17707      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 216        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 507        |\n",
      "|    total_timesteps | 18144      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 2.92       |\n",
      "|    critic_loss     | 0.0208     |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 18043      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 220        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 516        |\n",
      "|    total_timesteps | 18480      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 2.86       |\n",
      "|    critic_loss     | 0.0161     |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 18379      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 520\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 881387.31\n",
      "total_reward: -118612.69\n",
      "total_cost: 1007.71\n",
      "total_trades: 11205\n",
      "Sharpe: -2.324\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 224        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 525        |\n",
      "|    total_timesteps | 18816      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 3.14       |\n",
      "|    critic_loss     | 0.0311     |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 18715      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 228        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 534        |\n",
      "|    total_timesteps | 19152      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 3.04       |\n",
      "|    critic_loss     | 0.00246    |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 19051      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 530\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 881387.31\n",
      "total_reward: -118612.69\n",
      "total_cost: 1007.71\n",
      "total_trades: 11205\n",
      "Sharpe: -2.324\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 232        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 544        |\n",
      "|    total_timesteps | 19488      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 3.08       |\n",
      "|    critic_loss     | 0.0026     |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 19387      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 236        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 553        |\n",
      "|    total_timesteps | 19824      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 2.61       |\n",
      "|    critic_loss     | 0.00926    |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 19723      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 240        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 562        |\n",
      "|    total_timesteps | 20160      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 2.61       |\n",
      "|    critic_loss     | 0.0346     |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 20059      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 540\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 881387.31\n",
      "total_reward: -118612.69\n",
      "total_cost: 1007.71\n",
      "total_trades: 11205\n",
      "Sharpe: -2.324\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 244        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 571        |\n",
      "|    total_timesteps | 20496      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 3.56       |\n",
      "|    critic_loss     | 0.00816    |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 20395      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 248        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 580        |\n",
      "|    total_timesteps | 20832      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 2.91       |\n",
      "|    critic_loss     | 0.0136     |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 20731      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 550\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 881387.31\n",
      "total_reward: -118612.69\n",
      "total_cost: 1007.71\n",
      "total_trades: 11205\n",
      "Sharpe: -2.324\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 252        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 589        |\n",
      "|    total_timesteps | 21168      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 2.78       |\n",
      "|    critic_loss     | 0.0168     |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 21067      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 256        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 598        |\n",
      "|    total_timesteps | 21504      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 3.31       |\n",
      "|    critic_loss     | 0.0137     |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 21403      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 260        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 607        |\n",
      "|    total_timesteps | 21840      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 3.1        |\n",
      "|    critic_loss     | 0.0395     |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 21739      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 560\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 881387.31\n",
      "total_reward: -118612.69\n",
      "total_cost: 1007.71\n",
      "total_trades: 11205\n",
      "Sharpe: -2.324\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 264        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 616        |\n",
      "|    total_timesteps | 22176      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 3.52       |\n",
      "|    critic_loss     | 0.00169    |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 22075      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 268        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 625        |\n",
      "|    total_timesteps | 22512      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 3.41       |\n",
      "|    critic_loss     | 0.0101     |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 22411      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 570\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 881387.31\n",
      "total_reward: -118612.69\n",
      "total_cost: 1007.71\n",
      "total_trades: 11205\n",
      "Sharpe: -2.324\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 272        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 634        |\n",
      "|    total_timesteps | 22848      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 2.89       |\n",
      "|    critic_loss     | 0.0193     |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 22747      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 276        |\n",
      "|    fps             | 35         |\n",
      "|    time_elapsed    | 644        |\n",
      "|    total_timesteps | 23184      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 2.91       |\n",
      "|    critic_loss     | 0.00115    |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 23083      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 280        |\n",
      "|    fps             | 36         |\n",
      "|    time_elapsed    | 653        |\n",
      "|    total_timesteps | 23520      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 2.62       |\n",
      "|    critic_loss     | 0.161      |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 23419      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 580\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 881387.31\n",
      "total_reward: -118612.69\n",
      "total_cost: 1007.71\n",
      "total_trades: 11205\n",
      "Sharpe: -2.324\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 284        |\n",
      "|    fps             | 36         |\n",
      "|    time_elapsed    | 662        |\n",
      "|    total_timesteps | 23856      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 3.43       |\n",
      "|    critic_loss     | 0.00213    |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 23755      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 288        |\n",
      "|    fps             | 36         |\n",
      "|    time_elapsed    | 671        |\n",
      "|    total_timesteps | 24192      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 3.66       |\n",
      "|    critic_loss     | 0.0281     |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 24091      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 590\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 881387.31\n",
      "total_reward: -118612.69\n",
      "total_cost: 1007.71\n",
      "total_trades: 11205\n",
      "Sharpe: -2.324\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 292        |\n",
      "|    fps             | 36         |\n",
      "|    time_elapsed    | 680        |\n",
      "|    total_timesteps | 24528      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 2.32       |\n",
      "|    critic_loss     | 0.0434     |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 24427      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 296        |\n",
      "|    fps             | 36         |\n",
      "|    time_elapsed    | 689        |\n",
      "|    total_timesteps | 24864      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 3.6        |\n",
      "|    critic_loss     | 0.00694    |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 24763      |\n",
      "|    reward          | 0.41157126 |\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_ddpg = agent.train_model(model=model_ddpg,\n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=25000) if if_using_ddpg else None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T09:41:28.733682400Z",
     "start_time": "2024-02-26T09:29:55.410254400Z"
    }
   },
   "id": "7ea9efc373a3769",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Logging to results/ppo\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)\n",
    "\n",
    "if if_using_ppo:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/ppo'\n",
    "  new_logger_ppo = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_ppo.set_logger(new_logger_ppo)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T09:41:29.214179200Z",
     "start_time": "2024-02-26T09:41:28.734683Z"
    }
   },
   "id": "24548f788e424fc6",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 83, episode: 600\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 860963.79\n",
      "total_reward: -139036.21\n",
      "total_cost: 25506.15\n",
      "total_trades: 18204\n",
      "Sharpe: -2.779\n",
      "=================================\n",
      "day: 83, episode: 610\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 846373.13\n",
      "total_reward: -153626.87\n",
      "total_cost: 23513.66\n",
      "total_trades: 17965\n",
      "Sharpe: -3.254\n",
      "=================================\n",
      "day: 83, episode: 620\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 875855.30\n",
      "total_reward: -124144.70\n",
      "total_cost: 23080.96\n",
      "total_trades: 18094\n",
      "Sharpe: -2.690\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    fps             | 113        |\n",
      "|    iterations      | 1          |\n",
      "|    time_elapsed    | 18         |\n",
      "|    total_timesteps | 2048       |\n",
      "| train/             |            |\n",
      "|    reward          | -0.5291522 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 630\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 906750.21\n",
      "total_reward: -93249.79\n",
      "total_cost: 23793.44\n",
      "total_trades: 18076\n",
      "Sharpe: -2.046\n",
      "=================================\n",
      "day: 83, episode: 640\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 864702.74\n",
      "total_reward: -135297.26\n",
      "total_cost: 24142.20\n",
      "total_trades: 18068\n",
      "Sharpe: -2.437\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.105623186 |\n",
      "|    clip_fraction        | 0.615       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -367        |\n",
      "|    explained_variance   | 0.0465      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -2.85       |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0957     |\n",
      "|    reward               | 0.19549866  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 2.27        |\n",
      "-----------------------------------------\n",
      "day: 83, episode: 650\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 914977.25\n",
      "total_reward: -85022.75\n",
      "total_cost: 24263.24\n",
      "total_trades: 17834\n",
      "Sharpe: -1.515\n",
      "=================================\n",
      "day: 83, episode: 660\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 899347.99\n",
      "total_reward: -100652.01\n",
      "total_cost: 24620.27\n",
      "total_trades: 18164\n",
      "Sharpe: -1.911\n",
      "=================================\n",
      "day: 83, episode: 670\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 908407.12\n",
      "total_reward: -91592.88\n",
      "total_cost: 25588.14\n",
      "total_trades: 18284\n",
      "Sharpe: -2.000\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 105        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 58         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14731058 |\n",
      "|    clip_fraction        | 0.621      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -367       |\n",
      "|    explained_variance   | 0.471      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -2.82      |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0745    |\n",
      "|    reward               | -1.5058619 |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 2.31       |\n",
      "----------------------------------------\n",
      "day: 83, episode: 680\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 878241.99\n",
      "total_reward: -121758.01\n",
      "total_cost: 23845.81\n",
      "total_trades: 17976\n",
      "Sharpe: -2.377\n",
      "=================================\n",
      "day: 83, episode: 690\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 893923.58\n",
      "total_reward: -106076.42\n",
      "total_cost: 23183.93\n",
      "total_trades: 17843\n",
      "Sharpe: -2.112\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 77           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.1695157    |\n",
      "|    clip_fraction        | 0.661        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -369         |\n",
      "|    explained_variance   | 0.627        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -2.85        |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0587      |\n",
      "|    reward               | -0.058294717 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 1.93         |\n",
      "------------------------------------------\n",
      "day: 83, episode: 700\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 914894.76\n",
      "total_reward: -85105.24\n",
      "total_cost: 25996.36\n",
      "total_trades: 17745\n",
      "Sharpe: -1.634\n",
      "=================================\n",
      "day: 83, episode: 710\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 863117.88\n",
      "total_reward: -136882.12\n",
      "total_cost: 25067.49\n",
      "total_trades: 18255\n",
      "Sharpe: -3.070\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 104        |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 97         |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16765332 |\n",
      "|    clip_fraction        | 0.684      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -370       |\n",
      "|    explained_variance   | 0.72       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -2.62      |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0632    |\n",
      "|    reward               | -0.4984355 |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 1.85       |\n",
      "----------------------------------------\n",
      "day: 83, episode: 720\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 883403.70\n",
      "total_reward: -116596.30\n",
      "total_cost: 23255.47\n",
      "total_trades: 17467\n",
      "Sharpe: -2.554\n",
      "=================================\n",
      "day: 83, episode: 730\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 886471.76\n",
      "total_reward: -113528.24\n",
      "total_cost: 25357.91\n",
      "total_trades: 18165\n",
      "Sharpe: -2.610\n",
      "=================================\n",
      "day: 83, episode: 740\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 876857.32\n",
      "total_reward: -123142.68\n",
      "total_cost: 25117.54\n",
      "total_trades: 18116\n",
      "Sharpe: -2.243\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 118         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.19132215  |\n",
      "|    clip_fraction        | 0.637       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -370        |\n",
      "|    explained_variance   | 0.743       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -2.85       |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0396     |\n",
      "|    reward               | -0.63872486 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 2.04        |\n",
      "-----------------------------------------\n",
      "day: 83, episode: 750\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 926017.28\n",
      "total_reward: -73982.72\n",
      "total_cost: 24556.64\n",
      "total_trades: 18013\n",
      "Sharpe: -1.598\n",
      "=================================\n",
      "day: 83, episode: 760\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 895796.45\n",
      "total_reward: -104203.55\n",
      "total_cost: 24961.69\n",
      "total_trades: 17789\n",
      "Sharpe: -1.855\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 103        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 138        |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17295787 |\n",
      "|    clip_fraction        | 0.677      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -371       |\n",
      "|    explained_variance   | 0.763      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -3.02      |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0415    |\n",
      "|    reward               | -0.164573  |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 1.89       |\n",
      "----------------------------------------\n",
      "day: 83, episode: 770\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 941346.68\n",
      "total_reward: -58653.32\n",
      "total_cost: 25387.00\n",
      "total_trades: 17708\n",
      "Sharpe: -1.180\n",
      "=================================\n",
      "day: 83, episode: 780\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 942851.98\n",
      "total_reward: -57148.02\n",
      "total_cost: 20899.49\n",
      "total_trades: 16686\n",
      "Sharpe: -0.613\n",
      "=================================\n",
      "day: 83, episode: 790\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 858028.95\n",
      "total_reward: -141971.05\n",
      "total_cost: 24505.87\n",
      "total_trades: 17794\n",
      "Sharpe: -2.973\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 103         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 158         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.20549324  |\n",
      "|    clip_fraction        | 0.692       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -372        |\n",
      "|    explained_variance   | 0.787       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -2.91       |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0309     |\n",
      "|    reward               | -0.99593604 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 1.81        |\n",
      "-----------------------------------------\n",
      "day: 83, episode: 800\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 894510.45\n",
      "total_reward: -105489.55\n",
      "total_cost: 24459.11\n",
      "total_trades: 17425\n",
      "Sharpe: -1.968\n",
      "=================================\n",
      "day: 83, episode: 810\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 907798.31\n",
      "total_reward: -92201.69\n",
      "total_cost: 25613.67\n",
      "total_trades: 17734\n",
      "Sharpe: -1.847\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 103        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 177        |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24145214 |\n",
      "|    clip_fraction        | 0.633      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -373       |\n",
      "|    explained_variance   | 0.767      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -2.81      |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0502    |\n",
      "|    reward               | 1.614731   |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 1.84       |\n",
      "----------------------------------------\n",
      "day: 83, episode: 820\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 969128.46\n",
      "total_reward: -30871.54\n",
      "total_cost: 22233.34\n",
      "total_trades: 17063\n",
      "Sharpe: -0.517\n",
      "=================================\n",
      "day: 83, episode: 830\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 934506.61\n",
      "total_reward: -65493.39\n",
      "total_cost: 23325.58\n",
      "total_trades: 17017\n",
      "Sharpe: -1.171\n",
      "=================================\n",
      "day: 83, episode: 840\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 941897.79\n",
      "total_reward: -58102.21\n",
      "total_cost: 25414.87\n",
      "total_trades: 17450\n",
      "Sharpe: -1.002\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 103        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 197        |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.271958   |\n",
      "|    clip_fraction        | 0.734      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -374       |\n",
      "|    explained_variance   | 0.772      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -3.12      |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.0339    |\n",
      "|    reward               | -1.5296628 |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 1.59       |\n",
      "----------------------------------------\n",
      "day: 83, episode: 850\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 923119.52\n",
      "total_reward: -76880.48\n",
      "total_cost: 25119.16\n",
      "total_trades: 17720\n",
      "Sharpe: -1.220\n",
      "=================================\n",
      "day: 83, episode: 860\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 888397.97\n",
      "total_reward: -111602.03\n",
      "total_cost: 23932.95\n",
      "total_trades: 17581\n",
      "Sharpe: -1.968\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 104        |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 216        |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27440822 |\n",
      "|    clip_fraction        | 0.678      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -375       |\n",
      "|    explained_variance   | 0.751      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -2.71      |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.045     |\n",
      "|    reward               | 0.5983071  |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 1.86       |\n",
      "----------------------------------------\n",
      "day: 83, episode: 870\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 924879.82\n",
      "total_reward: -75120.18\n",
      "total_cost: 23936.40\n",
      "total_trades: 17403\n",
      "Sharpe: -1.618\n",
      "=================================\n",
      "day: 83, episode: 880\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 897114.76\n",
      "total_reward: -102885.24\n",
      "total_cost: 24702.98\n",
      "total_trades: 17657\n",
      "Sharpe: -2.146\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 104        |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 235        |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.323901   |\n",
      "|    clip_fraction        | 0.672      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -376       |\n",
      "|    explained_variance   | 0.666      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -3.08      |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | -0.04      |\n",
      "|    reward               | 0.14125004 |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 1.74       |\n",
      "----------------------------------------\n",
      "day: 83, episode: 890\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 932727.98\n",
      "total_reward: -67272.02\n",
      "total_cost: 20531.88\n",
      "total_trades: 16671\n",
      "Sharpe: -1.144\n",
      "=================================\n",
      "day: 83, episode: 900\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 917643.34\n",
      "total_reward: -82356.66\n",
      "total_cost: 25051.72\n",
      "total_trades: 17589\n",
      "Sharpe: -1.758\n",
      "=================================\n",
      "day: 83, episode: 910\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 940491.06\n",
      "total_reward: -59508.94\n",
      "total_cost: 22869.38\n",
      "total_trades: 17171\n",
      "Sharpe: -1.053\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 104        |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 254        |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29352385 |\n",
      "|    clip_fraction        | 0.69       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -378       |\n",
      "|    explained_variance   | 0.672      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -2.82      |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0294    |\n",
      "|    reward               | -0.6730938 |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 1.88       |\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name='ppo',\n",
    "                             total_timesteps=25000) if if_using_ppo else None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T09:45:45.679791600Z",
     "start_time": "2024-02-26T09:41:29.201175600Z"
    }
   },
   "id": "1a5512afd8fcef22",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 100, 'buffer_size': 10000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "Logging to results/td3\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "TD3_PARAMS = {\"batch_size\": 100, \n",
    "              \"buffer_size\": 10000, \n",
    "              \"learning_rate\": 0.001}\n",
    "\n",
    "model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)\n",
    "\n",
    "if if_using_td3:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/td3'\n",
    "  new_logger_td3 = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_td3.set_logger(new_logger_td3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T09:45:45.818183200Z",
     "start_time": "2024-02-26T09:45:45.691269900Z"
    }
   },
   "id": "431a072b0ef0c4d7",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 46          |\n",
      "|    time_elapsed    | 7           |\n",
      "|    total_timesteps | 336         |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 139         |\n",
      "|    critic_loss     | 6.83e+03    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 235         |\n",
      "|    reward          | -0.27877146 |\n",
      "------------------------------------\n",
      "day: 83, episode: 920\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 933384.20\n",
      "total_reward: -66615.80\n",
      "total_cost: 1033.80\n",
      "total_trades: 10756\n",
      "Sharpe: -1.221\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 8           |\n",
      "|    fps             | 39          |\n",
      "|    time_elapsed    | 16          |\n",
      "|    total_timesteps | 672         |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 42.2        |\n",
      "|    critic_loss     | 60.3        |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 571         |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 12          |\n",
      "|    fps             | 38          |\n",
      "|    time_elapsed    | 26          |\n",
      "|    total_timesteps | 1008        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 28          |\n",
      "|    critic_loss     | 8.32e+03    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 907         |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "day: 83, episode: 930\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 939886.02\n",
      "total_reward: -60113.98\n",
      "total_cost: 1031.44\n",
      "total_trades: 10813\n",
      "Sharpe: -1.117\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 16          |\n",
      "|    fps             | 38          |\n",
      "|    time_elapsed    | 35          |\n",
      "|    total_timesteps | 1344        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 20.6        |\n",
      "|    critic_loss     | 2.67e+03    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 1243        |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 20          |\n",
      "|    fps             | 37          |\n",
      "|    time_elapsed    | 44          |\n",
      "|    total_timesteps | 1680        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 3.23        |\n",
      "|    critic_loss     | 190         |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 1579        |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 24          |\n",
      "|    fps             | 37          |\n",
      "|    time_elapsed    | 54          |\n",
      "|    total_timesteps | 2016        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 9.45        |\n",
      "|    critic_loss     | 17.6        |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 1915        |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "day: 83, episode: 940\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 939886.02\n",
      "total_reward: -60113.98\n",
      "total_cost: 1031.44\n",
      "total_trades: 10813\n",
      "Sharpe: -1.117\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 28          |\n",
      "|    fps             | 37          |\n",
      "|    time_elapsed    | 63          |\n",
      "|    total_timesteps | 2352        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 9.23        |\n",
      "|    critic_loss     | 807         |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 2251        |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 32          |\n",
      "|    fps             | 36          |\n",
      "|    time_elapsed    | 72          |\n",
      "|    total_timesteps | 2688        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 7.58        |\n",
      "|    critic_loss     | 485         |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 2587        |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "day: 83, episode: 950\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 939886.02\n",
      "total_reward: -60113.98\n",
      "total_cost: 1031.44\n",
      "total_trades: 10813\n",
      "Sharpe: -1.117\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 36          |\n",
      "|    fps             | 36          |\n",
      "|    time_elapsed    | 82          |\n",
      "|    total_timesteps | 3024        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.77        |\n",
      "|    critic_loss     | 4.28        |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 2923        |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 40          |\n",
      "|    fps             | 36          |\n",
      "|    time_elapsed    | 91          |\n",
      "|    total_timesteps | 3360        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.51        |\n",
      "|    critic_loss     | 152         |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 3259        |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 44          |\n",
      "|    fps             | 36          |\n",
      "|    time_elapsed    | 101         |\n",
      "|    total_timesteps | 3696        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.98        |\n",
      "|    critic_loss     | 0.572       |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 3595        |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "day: 83, episode: 960\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 939886.02\n",
      "total_reward: -60113.98\n",
      "total_cost: 1031.44\n",
      "total_trades: 10813\n",
      "Sharpe: -1.117\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 48          |\n",
      "|    fps             | 36          |\n",
      "|    time_elapsed    | 110         |\n",
      "|    total_timesteps | 4032        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.63        |\n",
      "|    critic_loss     | 2.01        |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 3931        |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 52          |\n",
      "|    fps             | 36          |\n",
      "|    time_elapsed    | 119         |\n",
      "|    total_timesteps | 4368        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 7.27        |\n",
      "|    critic_loss     | 0.708       |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 4267        |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "day: 83, episode: 970\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 939886.02\n",
      "total_reward: -60113.98\n",
      "total_cost: 1031.44\n",
      "total_trades: 10813\n",
      "Sharpe: -1.117\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 56          |\n",
      "|    fps             | 36          |\n",
      "|    time_elapsed    | 129         |\n",
      "|    total_timesteps | 4704        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 8.4         |\n",
      "|    critic_loss     | 6.95        |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 4603        |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 60          |\n",
      "|    fps             | 36          |\n",
      "|    time_elapsed    | 138         |\n",
      "|    total_timesteps | 5040        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 8.16        |\n",
      "|    critic_loss     | 1.44        |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 4939        |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 64          |\n",
      "|    fps             | 36          |\n",
      "|    time_elapsed    | 148         |\n",
      "|    total_timesteps | 5376        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 8.35        |\n",
      "|    critic_loss     | 1.91        |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 5275        |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "day: 83, episode: 980\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 939886.02\n",
      "total_reward: -60113.98\n",
      "total_cost: 1031.44\n",
      "total_trades: 10813\n",
      "Sharpe: -1.117\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 68          |\n",
      "|    fps             | 36          |\n",
      "|    time_elapsed    | 157         |\n",
      "|    total_timesteps | 5712        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 7.19        |\n",
      "|    critic_loss     | 1.08        |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 5611        |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 72          |\n",
      "|    fps             | 36          |\n",
      "|    time_elapsed    | 166         |\n",
      "|    total_timesteps | 6048        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.67        |\n",
      "|    critic_loss     | 1.94        |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 5947        |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "day: 83, episode: 990\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 939886.02\n",
      "total_reward: -60113.98\n",
      "total_cost: 1031.44\n",
      "total_trades: 10813\n",
      "Sharpe: -1.117\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 76          |\n",
      "|    fps             | 36          |\n",
      "|    time_elapsed    | 176         |\n",
      "|    total_timesteps | 6384        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 7.64        |\n",
      "|    critic_loss     | 0.129       |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 6283        |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 80          |\n",
      "|    fps             | 36          |\n",
      "|    time_elapsed    | 185         |\n",
      "|    total_timesteps | 6720        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 7.82        |\n",
      "|    critic_loss     | 1.1         |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 6619        |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 84          |\n",
      "|    fps             | 36          |\n",
      "|    time_elapsed    | 195         |\n",
      "|    total_timesteps | 7056        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.55        |\n",
      "|    critic_loss     | 0.106       |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 6955        |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "day: 83, episode: 1000\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 939886.02\n",
      "total_reward: -60113.98\n",
      "total_cost: 1031.44\n",
      "total_trades: 10813\n",
      "Sharpe: -1.117\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 88          |\n",
      "|    fps             | 36          |\n",
      "|    time_elapsed    | 204         |\n",
      "|    total_timesteps | 7392        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 7.56        |\n",
      "|    critic_loss     | 8.95        |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 7291        |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 92          |\n",
      "|    fps             | 36          |\n",
      "|    time_elapsed    | 214         |\n",
      "|    total_timesteps | 7728        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 7.8         |\n",
      "|    critic_loss     | 54.1        |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 7627        |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "day: 83, episode: 1010\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 939886.02\n",
      "total_reward: -60113.98\n",
      "total_cost: 1031.44\n",
      "total_trades: 10813\n",
      "Sharpe: -1.117\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 96          |\n",
      "|    fps             | 36          |\n",
      "|    time_elapsed    | 223         |\n",
      "|    total_timesteps | 8064        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.75        |\n",
      "|    critic_loss     | 0.0854      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 7963        |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 100         |\n",
      "|    fps             | 36          |\n",
      "|    time_elapsed    | 232         |\n",
      "|    total_timesteps | 8400        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 7.05        |\n",
      "|    critic_loss     | 0.334       |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 8299        |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 104         |\n",
      "|    fps             | 36          |\n",
      "|    time_elapsed    | 242         |\n",
      "|    total_timesteps | 8736        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.52        |\n",
      "|    critic_loss     | 0.413       |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 8635        |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "day: 83, episode: 1020\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 939886.02\n",
      "total_reward: -60113.98\n",
      "total_cost: 1031.44\n",
      "total_trades: 10813\n",
      "Sharpe: -1.117\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 108         |\n",
      "|    fps             | 36          |\n",
      "|    time_elapsed    | 251         |\n",
      "|    total_timesteps | 9072        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.87        |\n",
      "|    critic_loss     | 1.32        |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 8971        |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 112         |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 261         |\n",
      "|    total_timesteps | 9408        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 5.83        |\n",
      "|    critic_loss     | 0.21        |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 9307        |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "day: 83, episode: 1030\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 939886.02\n",
      "total_reward: -60113.98\n",
      "total_cost: 1031.44\n",
      "total_trades: 10813\n",
      "Sharpe: -1.117\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 116         |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 271         |\n",
      "|    total_timesteps | 9744        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.33        |\n",
      "|    critic_loss     | 0.136       |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 9643        |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 120         |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 280         |\n",
      "|    total_timesteps | 10080       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.55        |\n",
      "|    critic_loss     | 0.0672      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 9979        |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 124         |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 290         |\n",
      "|    total_timesteps | 10416       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.22        |\n",
      "|    critic_loss     | 0.00503     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 10315       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "day: 83, episode: 1040\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 939886.02\n",
      "total_reward: -60113.98\n",
      "total_cost: 1031.44\n",
      "total_trades: 10813\n",
      "Sharpe: -1.117\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 128         |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 299         |\n",
      "|    total_timesteps | 10752       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 5.91        |\n",
      "|    critic_loss     | 0.00234     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 10651       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 132         |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 309         |\n",
      "|    total_timesteps | 11088       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.21        |\n",
      "|    critic_loss     | 0.0172      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 10987       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "day: 83, episode: 1050\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 939886.02\n",
      "total_reward: -60113.98\n",
      "total_cost: 1031.44\n",
      "total_trades: 10813\n",
      "Sharpe: -1.117\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 136         |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 319         |\n",
      "|    total_timesteps | 11424       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.27        |\n",
      "|    critic_loss     | 0.0427      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 11323       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 140         |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 328         |\n",
      "|    total_timesteps | 11760       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 7.18        |\n",
      "|    critic_loss     | 0.0646      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 11659       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 144         |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 337         |\n",
      "|    total_timesteps | 12096       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 7.57        |\n",
      "|    critic_loss     | 0.00321     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 11995       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "day: 83, episode: 1060\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 939886.02\n",
      "total_reward: -60113.98\n",
      "total_cost: 1031.44\n",
      "total_trades: 10813\n",
      "Sharpe: -1.117\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 148         |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 347         |\n",
      "|    total_timesteps | 12432       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 7.65        |\n",
      "|    critic_loss     | 0.000995    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 12331       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 152         |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 356         |\n",
      "|    total_timesteps | 12768       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 7.89        |\n",
      "|    critic_loss     | 0.00412     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 12667       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "day: 83, episode: 1070\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 939886.02\n",
      "total_reward: -60113.98\n",
      "total_cost: 1031.44\n",
      "total_trades: 10813\n",
      "Sharpe: -1.117\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 156         |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 366         |\n",
      "|    total_timesteps | 13104       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 7.59        |\n",
      "|    critic_loss     | 0.0101      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 13003       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 160         |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 375         |\n",
      "|    total_timesteps | 13440       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 7.13        |\n",
      "|    critic_loss     | 0.0509      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 13339       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 164         |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 385         |\n",
      "|    total_timesteps | 13776       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.97        |\n",
      "|    critic_loss     | 0.00788     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 13675       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "day: 83, episode: 1080\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 939886.02\n",
      "total_reward: -60113.98\n",
      "total_cost: 1031.44\n",
      "total_trades: 10813\n",
      "Sharpe: -1.117\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 168         |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 394         |\n",
      "|    total_timesteps | 14112       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 7.53        |\n",
      "|    critic_loss     | 0.00481     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 14011       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 172         |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 403         |\n",
      "|    total_timesteps | 14448       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 7.16        |\n",
      "|    critic_loss     | 0.00442     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 14347       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "day: 83, episode: 1090\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 939886.02\n",
      "total_reward: -60113.98\n",
      "total_cost: 1031.44\n",
      "total_trades: 10813\n",
      "Sharpe: -1.117\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 176         |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 413         |\n",
      "|    total_timesteps | 14784       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.82        |\n",
      "|    critic_loss     | 1.94        |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 14683       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 180         |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 422         |\n",
      "|    total_timesteps | 15120       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 7.12        |\n",
      "|    critic_loss     | 0.00923     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 15019       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 184         |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 432         |\n",
      "|    total_timesteps | 15456       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 7.08        |\n",
      "|    critic_loss     | 0.0098      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 15355       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "day: 83, episode: 1100\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 939886.02\n",
      "total_reward: -60113.98\n",
      "total_cost: 1031.44\n",
      "total_trades: 10813\n",
      "Sharpe: -1.117\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 188         |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 441         |\n",
      "|    total_timesteps | 15792       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.65        |\n",
      "|    critic_loss     | 0.0015      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 15691       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 192         |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 451         |\n",
      "|    total_timesteps | 16128       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.88        |\n",
      "|    critic_loss     | 0.0255      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 16027       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "day: 83, episode: 1110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 939886.02\n",
      "total_reward: -60113.98\n",
      "total_cost: 1031.44\n",
      "total_trades: 10813\n",
      "Sharpe: -1.117\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 196         |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 460         |\n",
      "|    total_timesteps | 16464       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.37        |\n",
      "|    critic_loss     | 0.0199      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 16363       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 200         |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 470         |\n",
      "|    total_timesteps | 16800       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.94        |\n",
      "|    critic_loss     | 0.0633      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 16699       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 204         |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 479         |\n",
      "|    total_timesteps | 17136       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.57        |\n",
      "|    critic_loss     | 0.0382      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 17035       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "day: 83, episode: 1120\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 939886.02\n",
      "total_reward: -60113.98\n",
      "total_cost: 1031.44\n",
      "total_trades: 10813\n",
      "Sharpe: -1.117\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 208         |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 489         |\n",
      "|    total_timesteps | 17472       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.26        |\n",
      "|    critic_loss     | 0.00888     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 17371       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 212         |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 498         |\n",
      "|    total_timesteps | 17808       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.39        |\n",
      "|    critic_loss     | 0.00816     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 17707       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "day: 83, episode: 1130\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 939886.02\n",
      "total_reward: -60113.98\n",
      "total_cost: 1031.44\n",
      "total_trades: 10813\n",
      "Sharpe: -1.117\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 216         |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 508         |\n",
      "|    total_timesteps | 18144       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 5.99        |\n",
      "|    critic_loss     | 0.0227      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 18043       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 220         |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 517         |\n",
      "|    total_timesteps | 18480       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.37        |\n",
      "|    critic_loss     | 0.0621      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 18379       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 224         |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 527         |\n",
      "|    total_timesteps | 18816       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.24        |\n",
      "|    critic_loss     | 0.00808     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 18715       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "day: 83, episode: 1140\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 939886.02\n",
      "total_reward: -60113.98\n",
      "total_cost: 1031.44\n",
      "total_trades: 10813\n",
      "Sharpe: -1.117\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 228         |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 536         |\n",
      "|    total_timesteps | 19152       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.41        |\n",
      "|    critic_loss     | 0.0305      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 19051       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 232         |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 546         |\n",
      "|    total_timesteps | 19488       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.49        |\n",
      "|    critic_loss     | 0.00359     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 19387       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "day: 83, episode: 1150\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 939886.02\n",
      "total_reward: -60113.98\n",
      "total_cost: 1031.44\n",
      "total_trades: 10813\n",
      "Sharpe: -1.117\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 236         |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 555         |\n",
      "|    total_timesteps | 19824       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.21        |\n",
      "|    critic_loss     | 0.0648      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 19723       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 240         |\n",
      "|    fps             | 34          |\n",
      "|    time_elapsed    | 589         |\n",
      "|    total_timesteps | 20160       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 5.57        |\n",
      "|    critic_loss     | 0.113       |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 20059       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 244         |\n",
      "|    fps             | 34          |\n",
      "|    time_elapsed    | 598         |\n",
      "|    total_timesteps | 20496       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.18        |\n",
      "|    critic_loss     | 0.142       |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 20395       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "day: 83, episode: 1160\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 939886.02\n",
      "total_reward: -60113.98\n",
      "total_cost: 1031.44\n",
      "total_trades: 10813\n",
      "Sharpe: -1.117\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 248         |\n",
      "|    fps             | 34          |\n",
      "|    time_elapsed    | 607         |\n",
      "|    total_timesteps | 20832       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.25        |\n",
      "|    critic_loss     | 0.07        |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 20731       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 252         |\n",
      "|    fps             | 34          |\n",
      "|    time_elapsed    | 617         |\n",
      "|    total_timesteps | 21168       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.07        |\n",
      "|    critic_loss     | 0.288       |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 21067       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "day: 83, episode: 1170\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 939886.02\n",
      "total_reward: -60113.98\n",
      "total_cost: 1031.44\n",
      "total_trades: 10813\n",
      "Sharpe: -1.117\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 256         |\n",
      "|    fps             | 34          |\n",
      "|    time_elapsed    | 626         |\n",
      "|    total_timesteps | 21504       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 5.95        |\n",
      "|    critic_loss     | 0.265       |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 21403       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 260         |\n",
      "|    fps             | 34          |\n",
      "|    time_elapsed    | 636         |\n",
      "|    total_timesteps | 21840       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.05        |\n",
      "|    critic_loss     | 0.0803      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 21739       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 264         |\n",
      "|    fps             | 34          |\n",
      "|    time_elapsed    | 645         |\n",
      "|    total_timesteps | 22176       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 5.96        |\n",
      "|    critic_loss     | 0.0339      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 22075       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "day: 83, episode: 1180\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 939886.02\n",
      "total_reward: -60113.98\n",
      "total_cost: 1031.44\n",
      "total_trades: 10813\n",
      "Sharpe: -1.117\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 268         |\n",
      "|    fps             | 34          |\n",
      "|    time_elapsed    | 654         |\n",
      "|    total_timesteps | 22512       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.45        |\n",
      "|    critic_loss     | 0.0135      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 22411       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 272         |\n",
      "|    fps             | 34          |\n",
      "|    time_elapsed    | 664         |\n",
      "|    total_timesteps | 22848       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.58        |\n",
      "|    critic_loss     | 0.0316      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 22747       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "day: 83, episode: 1190\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 939886.02\n",
      "total_reward: -60113.98\n",
      "total_cost: 1031.44\n",
      "total_trades: 10813\n",
      "Sharpe: -1.117\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 276         |\n",
      "|    fps             | 34          |\n",
      "|    time_elapsed    | 673         |\n",
      "|    total_timesteps | 23184       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.39        |\n",
      "|    critic_loss     | 0.0186      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 23083       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 280         |\n",
      "|    fps             | 34          |\n",
      "|    time_elapsed    | 683         |\n",
      "|    total_timesteps | 23520       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.09        |\n",
      "|    critic_loss     | 0.00483     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 23419       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 284         |\n",
      "|    fps             | 34          |\n",
      "|    time_elapsed    | 692         |\n",
      "|    total_timesteps | 23856       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 5.83        |\n",
      "|    critic_loss     | 0.00499     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 23755       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "day: 83, episode: 1200\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 939886.02\n",
      "total_reward: -60113.98\n",
      "total_cost: 1031.44\n",
      "total_trades: 10813\n",
      "Sharpe: -1.117\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 288         |\n",
      "|    fps             | 34          |\n",
      "|    time_elapsed    | 702         |\n",
      "|    total_timesteps | 24192       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.08        |\n",
      "|    critic_loss     | 0.0516      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 24091       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 292         |\n",
      "|    fps             | 34          |\n",
      "|    time_elapsed    | 711         |\n",
      "|    total_timesteps | 24528       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 5.53        |\n",
      "|    critic_loss     | 0.0158      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 24427       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n",
      "day: 83, episode: 1210\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 939886.02\n",
      "total_reward: -60113.98\n",
      "total_cost: 1031.44\n",
      "total_trades: 10813\n",
      "Sharpe: -1.117\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 296         |\n",
      "|    fps             | 34          |\n",
      "|    time_elapsed    | 720         |\n",
      "|    total_timesteps | 24864       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 5.36        |\n",
      "|    critic_loss     | 0.00742     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 24763       |\n",
      "|    reward          | -0.13647366 |\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_td3 = agent.train_model(model=model_td3, \n",
    "                             tb_log_name='td3',\n",
    "                             total_timesteps=25000) if if_using_td3 else None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T09:57:50.562921200Z",
     "start_time": "2024-02-26T09:45:45.813182Z"
    }
   },
   "id": "3c64dc840cbe0385",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 10000, 'learning_rate': 0.0001, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
      "Using cuda device\n",
      "Logging to results/sac\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 10000,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"learning_starts\": 100,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "\n",
    "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)\n",
    "\n",
    "if if_using_sac:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/sac'\n",
    "  new_logger_sac = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_sac.set_logger(new_logger_sac)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T09:57:50.978320500Z",
     "start_time": "2024-02-26T09:57:50.579352Z"
    }
   },
   "id": "6d2015ce8f6bfd4a",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 38        |\n",
      "|    time_elapsed    | 8         |\n",
      "|    total_timesteps | 336       |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 109       |\n",
      "|    critic_loss     | 4.12e+03  |\n",
      "|    ent_coef        | 0.101     |\n",
      "|    ent_coef_loss   | -161      |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 235       |\n",
      "|    reward          | 0.4303629 |\n",
      "----------------------------------\n",
      "day: 83, episode: 1220\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 856582.87\n",
      "total_reward: -143417.13\n",
      "total_cost: 21648.06\n",
      "total_trades: 17713\n",
      "Sharpe: -2.764\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 8           |\n",
      "|    fps             | 32          |\n",
      "|    time_elapsed    | 20          |\n",
      "|    total_timesteps | 672         |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 41.6        |\n",
      "|    critic_loss     | 8.29e+03    |\n",
      "|    ent_coef        | 0.0992      |\n",
      "|    ent_coef_loss   | -829        |\n",
      "|    learning_rate   | 0.0001      |\n",
      "|    n_updates       | 571         |\n",
      "|    reward          | 0.026727265 |\n",
      "------------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 12         |\n",
      "|    fps             | 30         |\n",
      "|    time_elapsed    | 32         |\n",
      "|    total_timesteps | 1008       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 7.47       |\n",
      "|    critic_loss     | 620        |\n",
      "|    ent_coef        | 0.0959     |\n",
      "|    ent_coef_loss   | -1.02e+03  |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 907        |\n",
      "|    reward          | 0.26512727 |\n",
      "-----------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 16          |\n",
      "|    fps             | 29          |\n",
      "|    time_elapsed    | 44          |\n",
      "|    total_timesteps | 1344        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -12.9       |\n",
      "|    critic_loss     | 556         |\n",
      "|    ent_coef        | 0.0928      |\n",
      "|    ent_coef_loss   | -1.03e+03   |\n",
      "|    learning_rate   | 0.0001      |\n",
      "|    n_updates       | 1243        |\n",
      "|    reward          | -0.08279553 |\n",
      "------------------------------------\n",
      "day: 83, episode: 1230\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 852023.36\n",
      "total_reward: -147976.64\n",
      "total_cost: 20750.30\n",
      "total_trades: 18016\n",
      "Sharpe: -3.022\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 20          |\n",
      "|    fps             | 29          |\n",
      "|    time_elapsed    | 56          |\n",
      "|    total_timesteps | 1680        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -40.3       |\n",
      "|    critic_loss     | 375         |\n",
      "|    ent_coef        | 0.0897      |\n",
      "|    ent_coef_loss   | -1.04e+03   |\n",
      "|    learning_rate   | 0.0001      |\n",
      "|    n_updates       | 1579        |\n",
      "|    reward          | -0.42012823 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 24          |\n",
      "|    fps             | 29          |\n",
      "|    time_elapsed    | 68          |\n",
      "|    total_timesteps | 2016        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -63.6       |\n",
      "|    critic_loss     | 57.6        |\n",
      "|    ent_coef        | 0.0868      |\n",
      "|    ent_coef_loss   | -1.06e+03   |\n",
      "|    learning_rate   | 0.0001      |\n",
      "|    n_updates       | 1915        |\n",
      "|    reward          | -0.34143856 |\n",
      "------------------------------------\n",
      "day: 83, episode: 1240\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 838211.83\n",
      "total_reward: -161788.17\n",
      "total_cost: 19978.38\n",
      "total_trades: 18128\n",
      "Sharpe: -3.070\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 28         |\n",
      "|    fps             | 29         |\n",
      "|    time_elapsed    | 80         |\n",
      "|    total_timesteps | 2352       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -81.9      |\n",
      "|    critic_loss     | 129        |\n",
      "|    ent_coef        | 0.0839     |\n",
      "|    ent_coef_loss   | -1.07e+03  |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 2251       |\n",
      "|    reward          | -0.3518196 |\n",
      "-----------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 32          |\n",
      "|    fps             | 28          |\n",
      "|    time_elapsed    | 93          |\n",
      "|    total_timesteps | 2688        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -112        |\n",
      "|    critic_loss     | 17.2        |\n",
      "|    ent_coef        | 0.0811      |\n",
      "|    ent_coef_loss   | -1.09e+03   |\n",
      "|    learning_rate   | 0.0001      |\n",
      "|    n_updates       | 2587        |\n",
      "|    reward          | -0.18641913 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 36          |\n",
      "|    fps             | 28          |\n",
      "|    time_elapsed    | 105         |\n",
      "|    total_timesteps | 3024        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -128        |\n",
      "|    critic_loss     | 34.7        |\n",
      "|    ent_coef        | 0.0785      |\n",
      "|    ent_coef_loss   | -1.1e+03    |\n",
      "|    learning_rate   | 0.0001      |\n",
      "|    n_updates       | 2923        |\n",
      "|    reward          | -0.25269678 |\n",
      "------------------------------------\n",
      "day: 83, episode: 1250\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 862601.71\n",
      "total_reward: -137398.29\n",
      "total_cost: 19694.48\n",
      "total_trades: 17852\n",
      "Sharpe: -2.187\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 40          |\n",
      "|    fps             | 28          |\n",
      "|    time_elapsed    | 117         |\n",
      "|    total_timesteps | 3360        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -152        |\n",
      "|    critic_loss     | 8.97        |\n",
      "|    ent_coef        | 0.0759      |\n",
      "|    ent_coef_loss   | -1.11e+03   |\n",
      "|    learning_rate   | 0.0001      |\n",
      "|    n_updates       | 3259        |\n",
      "|    reward          | -0.17947513 |\n",
      "------------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 44         |\n",
      "|    fps             | 28         |\n",
      "|    time_elapsed    | 129        |\n",
      "|    total_timesteps | 3696       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -165       |\n",
      "|    critic_loss     | 10.1       |\n",
      "|    ent_coef        | 0.0734     |\n",
      "|    ent_coef_loss   | -1.13e+03  |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 3595       |\n",
      "|    reward          | -0.2685854 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 1260\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 920503.63\n",
      "total_reward: -79496.37\n",
      "total_cost: 20163.88\n",
      "total_trades: 18056\n",
      "Sharpe: -1.838\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 48           |\n",
      "|    fps             | 28           |\n",
      "|    time_elapsed    | 141          |\n",
      "|    total_timesteps | 4032         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -174         |\n",
      "|    critic_loss     | 25.8         |\n",
      "|    ent_coef        | 0.071        |\n",
      "|    ent_coef_loss   | -1.14e+03    |\n",
      "|    learning_rate   | 0.0001       |\n",
      "|    n_updates       | 3931         |\n",
      "|    reward          | -0.089935176 |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 52          |\n",
      "|    fps             | 28          |\n",
      "|    time_elapsed    | 153         |\n",
      "|    total_timesteps | 4368        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -188        |\n",
      "|    critic_loss     | 16.9        |\n",
      "|    ent_coef        | 0.0686      |\n",
      "|    ent_coef_loss   | -1.15e+03   |\n",
      "|    learning_rate   | 0.0001      |\n",
      "|    n_updates       | 4267        |\n",
      "|    reward          | -0.45115343 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 56          |\n",
      "|    fps             | 28          |\n",
      "|    time_elapsed    | 165         |\n",
      "|    total_timesteps | 4704        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -210        |\n",
      "|    critic_loss     | 15          |\n",
      "|    ent_coef        | 0.0664      |\n",
      "|    ent_coef_loss   | -1.17e+03   |\n",
      "|    learning_rate   | 0.0001      |\n",
      "|    n_updates       | 4603        |\n",
      "|    reward          | -0.18668383 |\n",
      "------------------------------------\n",
      "day: 83, episode: 1270\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 882854.24\n",
      "total_reward: -117145.76\n",
      "total_cost: 17185.86\n",
      "total_trades: 17599\n",
      "Sharpe: -2.645\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 60         |\n",
      "|    fps             | 28         |\n",
      "|    time_elapsed    | 177        |\n",
      "|    total_timesteps | 5040       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -217       |\n",
      "|    critic_loss     | 13.1       |\n",
      "|    ent_coef        | 0.0642     |\n",
      "|    ent_coef_loss   | -1.18e+03  |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 4939       |\n",
      "|    reward          | -0.1069789 |\n",
      "-----------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 64          |\n",
      "|    fps             | 28          |\n",
      "|    time_elapsed    | 189         |\n",
      "|    total_timesteps | 5376        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -223        |\n",
      "|    critic_loss     | 31.8        |\n",
      "|    ent_coef        | 0.0621      |\n",
      "|    ent_coef_loss   | -1.19e+03   |\n",
      "|    learning_rate   | 0.0001      |\n",
      "|    n_updates       | 5275        |\n",
      "|    reward          | -0.21614145 |\n",
      "------------------------------------\n",
      "day: 83, episode: 1280\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 894668.67\n",
      "total_reward: -105331.33\n",
      "total_cost: 15687.78\n",
      "total_trades: 17247\n",
      "Sharpe: -2.294\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 68          |\n",
      "|    fps             | 28          |\n",
      "|    time_elapsed    | 202         |\n",
      "|    total_timesteps | 5712        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -241        |\n",
      "|    critic_loss     | 380         |\n",
      "|    ent_coef        | 0.06        |\n",
      "|    ent_coef_loss   | -1.2e+03    |\n",
      "|    learning_rate   | 0.0001      |\n",
      "|    n_updates       | 5611        |\n",
      "|    reward          | 0.033155914 |\n",
      "------------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 72         |\n",
      "|    fps             | 28         |\n",
      "|    time_elapsed    | 214        |\n",
      "|    total_timesteps | 6048       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -242       |\n",
      "|    critic_loss     | 8.9        |\n",
      "|    ent_coef        | 0.058      |\n",
      "|    ent_coef_loss   | -1.22e+03  |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 5947       |\n",
      "|    reward          | 0.45429304 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 76         |\n",
      "|    fps             | 28         |\n",
      "|    time_elapsed    | 225        |\n",
      "|    total_timesteps | 6384       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -254       |\n",
      "|    critic_loss     | 8.27       |\n",
      "|    ent_coef        | 0.0561     |\n",
      "|    ent_coef_loss   | -1.23e+03  |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 6283       |\n",
      "|    reward          | 0.10043071 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 1290\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 899474.83\n",
      "total_reward: -100525.17\n",
      "total_cost: 15166.70\n",
      "total_trades: 17241\n",
      "Sharpe: -2.371\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 80         |\n",
      "|    fps             | 28         |\n",
      "|    time_elapsed    | 237        |\n",
      "|    total_timesteps | 6720       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -278       |\n",
      "|    critic_loss     | 4.3        |\n",
      "|    ent_coef        | 0.0543     |\n",
      "|    ent_coef_loss   | -1.23e+03  |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 6619       |\n",
      "|    reward          | 0.07707548 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 84         |\n",
      "|    fps             | 28         |\n",
      "|    time_elapsed    | 249        |\n",
      "|    total_timesteps | 7056       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -262       |\n",
      "|    critic_loss     | 6.2        |\n",
      "|    ent_coef        | 0.0525     |\n",
      "|    ent_coef_loss   | -1.25e+03  |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 6955       |\n",
      "|    reward          | 0.25302064 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 1300\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 933476.53\n",
      "total_reward: -66523.47\n",
      "total_cost: 13099.14\n",
      "total_trades: 16562\n",
      "Sharpe: -1.517\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 88         |\n",
      "|    fps             | 28         |\n",
      "|    time_elapsed    | 260        |\n",
      "|    total_timesteps | 7392       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -264       |\n",
      "|    critic_loss     | 7.49       |\n",
      "|    ent_coef        | 0.0508     |\n",
      "|    ent_coef_loss   | -1.25e+03  |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 7291       |\n",
      "|    reward          | 0.22465625 |\n",
      "-----------------------------------\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 92           |\n",
      "|    fps             | 28           |\n",
      "|    time_elapsed    | 273          |\n",
      "|    total_timesteps | 7728         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -272         |\n",
      "|    critic_loss     | 8.72         |\n",
      "|    ent_coef        | 0.0491       |\n",
      "|    ent_coef_loss   | -1.26e+03    |\n",
      "|    learning_rate   | 0.0001       |\n",
      "|    n_updates       | 7627         |\n",
      "|    reward          | -0.055100985 |\n",
      "-------------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 96         |\n",
      "|    fps             | 28         |\n",
      "|    time_elapsed    | 284        |\n",
      "|    total_timesteps | 8064       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -256       |\n",
      "|    critic_loss     | 7.62       |\n",
      "|    ent_coef        | 0.0475     |\n",
      "|    ent_coef_loss   | -1.27e+03  |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 7963       |\n",
      "|    reward          | 0.06610748 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 1310\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 936548.33\n",
      "total_reward: -63451.67\n",
      "total_cost: 11844.49\n",
      "total_trades: 16186\n",
      "Sharpe: -1.415\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 100          |\n",
      "|    fps             | 28           |\n",
      "|    time_elapsed    | 296          |\n",
      "|    total_timesteps | 8400         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -268         |\n",
      "|    critic_loss     | 13           |\n",
      "|    ent_coef        | 0.046        |\n",
      "|    ent_coef_loss   | -1.28e+03    |\n",
      "|    learning_rate   | 0.0001       |\n",
      "|    n_updates       | 8299         |\n",
      "|    reward          | -0.004970312 |\n",
      "-------------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 104        |\n",
      "|    fps             | 28         |\n",
      "|    time_elapsed    | 307        |\n",
      "|    total_timesteps | 8736       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -275       |\n",
      "|    critic_loss     | 33.4       |\n",
      "|    ent_coef        | 0.0445     |\n",
      "|    ent_coef_loss   | -1.29e+03  |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 8635       |\n",
      "|    reward          | 0.11695973 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 1320\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 908658.05\n",
      "total_reward: -91341.95\n",
      "total_cost: 11474.78\n",
      "total_trades: 15898\n",
      "Sharpe: -2.128\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 108        |\n",
      "|    fps             | 28         |\n",
      "|    time_elapsed    | 319        |\n",
      "|    total_timesteps | 9072       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -274       |\n",
      "|    critic_loss     | 8.46       |\n",
      "|    ent_coef        | 0.043      |\n",
      "|    ent_coef_loss   | -1.3e+03   |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 8971       |\n",
      "|    reward          | -0.1337925 |\n",
      "-----------------------------------\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 112          |\n",
      "|    fps             | 28           |\n",
      "|    time_elapsed    | 331          |\n",
      "|    total_timesteps | 9408         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -267         |\n",
      "|    critic_loss     | 12.9         |\n",
      "|    ent_coef        | 0.0416       |\n",
      "|    ent_coef_loss   | -1.31e+03    |\n",
      "|    learning_rate   | 0.0001       |\n",
      "|    n_updates       | 9307         |\n",
      "|    reward          | -0.026808543 |\n",
      "-------------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 116        |\n",
      "|    fps             | 28         |\n",
      "|    time_elapsed    | 342        |\n",
      "|    total_timesteps | 9744       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -290       |\n",
      "|    critic_loss     | 16.5       |\n",
      "|    ent_coef        | 0.0402     |\n",
      "|    ent_coef_loss   | -1.32e+03  |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 9643       |\n",
      "|    reward          | 0.06309801 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 1330\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 926754.30\n",
      "total_reward: -73245.70\n",
      "total_cost: 9975.45\n",
      "total_trades: 15548\n",
      "Sharpe: -1.682\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 120        |\n",
      "|    fps             | 28         |\n",
      "|    time_elapsed    | 354        |\n",
      "|    total_timesteps | 10080      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -271       |\n",
      "|    critic_loss     | 40.3       |\n",
      "|    ent_coef        | 0.0389     |\n",
      "|    ent_coef_loss   | -1.33e+03  |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 9979       |\n",
      "|    reward          | 0.06910718 |\n",
      "-----------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 124         |\n",
      "|    fps             | 28          |\n",
      "|    time_elapsed    | 365         |\n",
      "|    total_timesteps | 10416       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -285        |\n",
      "|    critic_loss     | 8.62        |\n",
      "|    ent_coef        | 0.0377      |\n",
      "|    ent_coef_loss   | -1.34e+03   |\n",
      "|    learning_rate   | 0.0001      |\n",
      "|    n_updates       | 10315       |\n",
      "|    reward          | -0.16130576 |\n",
      "------------------------------------\n",
      "day: 83, episode: 1340\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 892686.47\n",
      "total_reward: -107313.53\n",
      "total_cost: 10104.51\n",
      "total_trades: 15621\n",
      "Sharpe: -2.667\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 128        |\n",
      "|    fps             | 28         |\n",
      "|    time_elapsed    | 377        |\n",
      "|    total_timesteps | 10752      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -269       |\n",
      "|    critic_loss     | 4.12       |\n",
      "|    ent_coef        | 0.0364     |\n",
      "|    ent_coef_loss   | -1.35e+03  |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 10651      |\n",
      "|    reward          | 0.06550687 |\n",
      "-----------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 132         |\n",
      "|    fps             | 28          |\n",
      "|    time_elapsed    | 388         |\n",
      "|    total_timesteps | 11088       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -269        |\n",
      "|    critic_loss     | 66.6        |\n",
      "|    ent_coef        | 0.0352      |\n",
      "|    ent_coef_loss   | -1.36e+03   |\n",
      "|    learning_rate   | 0.0001      |\n",
      "|    n_updates       | 10987       |\n",
      "|    reward          | -0.02124014 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 136         |\n",
      "|    fps             | 28          |\n",
      "|    time_elapsed    | 400         |\n",
      "|    total_timesteps | 11424       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -263        |\n",
      "|    critic_loss     | 12          |\n",
      "|    ent_coef        | 0.0341      |\n",
      "|    ent_coef_loss   | -1.37e+03   |\n",
      "|    learning_rate   | 0.0001      |\n",
      "|    n_updates       | 11323       |\n",
      "|    reward          | -0.15576725 |\n",
      "------------------------------------\n",
      "day: 83, episode: 1350\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 896838.61\n",
      "total_reward: -103161.39\n",
      "total_cost: 10033.97\n",
      "total_trades: 15533\n",
      "Sharpe: -2.561\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 140        |\n",
      "|    fps             | 28         |\n",
      "|    time_elapsed    | 411        |\n",
      "|    total_timesteps | 11760      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -268       |\n",
      "|    critic_loss     | 38         |\n",
      "|    ent_coef        | 0.033      |\n",
      "|    ent_coef_loss   | -1.38e+03  |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 11659      |\n",
      "|    reward          | 0.11598394 |\n",
      "-----------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 144         |\n",
      "|    fps             | 28          |\n",
      "|    time_elapsed    | 423         |\n",
      "|    total_timesteps | 12096       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -262        |\n",
      "|    critic_loss     | 5.11        |\n",
      "|    ent_coef        | 0.0319      |\n",
      "|    ent_coef_loss   | -1.4e+03    |\n",
      "|    learning_rate   | 0.0001      |\n",
      "|    n_updates       | 11995       |\n",
      "|    reward          | -0.16836207 |\n",
      "------------------------------------\n",
      "day: 83, episode: 1360\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 942296.63\n",
      "total_reward: -57703.37\n",
      "total_cost: 8855.25\n",
      "total_trades: 15162\n",
      "Sharpe: -1.409\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 148         |\n",
      "|    fps             | 28          |\n",
      "|    time_elapsed    | 435         |\n",
      "|    total_timesteps | 12432       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -216        |\n",
      "|    critic_loss     | 10.3        |\n",
      "|    ent_coef        | 0.0308      |\n",
      "|    ent_coef_loss   | -1.41e+03   |\n",
      "|    learning_rate   | 0.0001      |\n",
      "|    n_updates       | 12331       |\n",
      "|    reward          | 0.044330943 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 152         |\n",
      "|    fps             | 28          |\n",
      "|    time_elapsed    | 447         |\n",
      "|    total_timesteps | 12768       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -243        |\n",
      "|    critic_loss     | 6.02        |\n",
      "|    ent_coef        | 0.0298      |\n",
      "|    ent_coef_loss   | -1.43e+03   |\n",
      "|    learning_rate   | 0.0001      |\n",
      "|    n_updates       | 12667       |\n",
      "|    reward          | -0.23759508 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 156         |\n",
      "|    fps             | 28          |\n",
      "|    time_elapsed    | 459         |\n",
      "|    total_timesteps | 13104       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -237        |\n",
      "|    critic_loss     | 2.39        |\n",
      "|    ent_coef        | 0.0288      |\n",
      "|    ent_coef_loss   | -1.44e+03   |\n",
      "|    learning_rate   | 0.0001      |\n",
      "|    n_updates       | 13003       |\n",
      "|    reward          | -0.13611974 |\n",
      "------------------------------------\n",
      "day: 83, episode: 1370\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 943299.02\n",
      "total_reward: -56700.98\n",
      "total_cost: 9197.81\n",
      "total_trades: 15414\n",
      "Sharpe: -1.357\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 160         |\n",
      "|    fps             | 28          |\n",
      "|    time_elapsed    | 471         |\n",
      "|    total_timesteps | 13440       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -242        |\n",
      "|    critic_loss     | 18.7        |\n",
      "|    ent_coef        | 0.0279      |\n",
      "|    ent_coef_loss   | -1.46e+03   |\n",
      "|    learning_rate   | 0.0001      |\n",
      "|    n_updates       | 13339       |\n",
      "|    reward          | 0.057802297 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 164         |\n",
      "|    fps             | 28          |\n",
      "|    time_elapsed    | 482         |\n",
      "|    total_timesteps | 13776       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -222        |\n",
      "|    critic_loss     | 1.99        |\n",
      "|    ent_coef        | 0.0269      |\n",
      "|    ent_coef_loss   | -1.47e+03   |\n",
      "|    learning_rate   | 0.0001      |\n",
      "|    n_updates       | 13675       |\n",
      "|    reward          | -0.08504879 |\n",
      "------------------------------------\n",
      "day: 83, episode: 1380\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 918551.66\n",
      "total_reward: -81448.34\n",
      "total_cost: 9331.53\n",
      "total_trades: 15555\n",
      "Sharpe: -1.943\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/              |               |\n",
      "|    episodes        | 168           |\n",
      "|    fps             | 28            |\n",
      "|    time_elapsed    | 494           |\n",
      "|    total_timesteps | 14112         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -247          |\n",
      "|    critic_loss     | 2.02          |\n",
      "|    ent_coef        | 0.026         |\n",
      "|    ent_coef_loss   | -1.49e+03     |\n",
      "|    learning_rate   | 0.0001        |\n",
      "|    n_updates       | 14011         |\n",
      "|    reward          | -0.0064511234 |\n",
      "--------------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 172        |\n",
      "|    fps             | 28         |\n",
      "|    time_elapsed    | 506        |\n",
      "|    total_timesteps | 14448      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -233       |\n",
      "|    critic_loss     | 10.8       |\n",
      "|    ent_coef        | 0.0252     |\n",
      "|    ent_coef_loss   | -1.51e+03  |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 14347      |\n",
      "|    reward          | 0.07610986 |\n",
      "-----------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 176         |\n",
      "|    fps             | 28          |\n",
      "|    time_elapsed    | 517         |\n",
      "|    total_timesteps | 14784       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -229        |\n",
      "|    critic_loss     | 40.4        |\n",
      "|    ent_coef        | 0.0243      |\n",
      "|    ent_coef_loss   | -1.53e+03   |\n",
      "|    learning_rate   | 0.0001      |\n",
      "|    n_updates       | 14683       |\n",
      "|    reward          | -0.07855102 |\n",
      "------------------------------------\n",
      "day: 83, episode: 1390\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 943148.55\n",
      "total_reward: -56851.45\n",
      "total_cost: 10929.81\n",
      "total_trades: 15796\n",
      "Sharpe: -1.354\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 180         |\n",
      "|    fps             | 28          |\n",
      "|    time_elapsed    | 529         |\n",
      "|    total_timesteps | 15120       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -198        |\n",
      "|    critic_loss     | 2.7         |\n",
      "|    ent_coef        | 0.0235      |\n",
      "|    ent_coef_loss   | -1.55e+03   |\n",
      "|    learning_rate   | 0.0001      |\n",
      "|    n_updates       | 15019       |\n",
      "|    reward          | 0.047212187 |\n",
      "------------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 184        |\n",
      "|    fps             | 28         |\n",
      "|    time_elapsed    | 540        |\n",
      "|    total_timesteps | 15456      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -216       |\n",
      "|    critic_loss     | 1.62       |\n",
      "|    ent_coef        | 0.0228     |\n",
      "|    ent_coef_loss   | -1.56e+03  |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 15355      |\n",
      "|    reward          | 0.07650126 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 1400\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 958177.15\n",
      "total_reward: -41822.85\n",
      "total_cost: 8808.60\n",
      "total_trades: 15118\n",
      "Sharpe: -0.941\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 188         |\n",
      "|    fps             | 28          |\n",
      "|    time_elapsed    | 552         |\n",
      "|    total_timesteps | 15792       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -203        |\n",
      "|    critic_loss     | 2.75        |\n",
      "|    ent_coef        | 0.022       |\n",
      "|    ent_coef_loss   | -1.56e+03   |\n",
      "|    learning_rate   | 0.0001      |\n",
      "|    n_updates       | 15691       |\n",
      "|    reward          | -0.08688166 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 192          |\n",
      "|    fps             | 28           |\n",
      "|    time_elapsed    | 564          |\n",
      "|    total_timesteps | 16128        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -206         |\n",
      "|    critic_loss     | 1.42         |\n",
      "|    ent_coef        | 0.0213       |\n",
      "|    ent_coef_loss   | -1.58e+03    |\n",
      "|    learning_rate   | 0.0001       |\n",
      "|    n_updates       | 16027        |\n",
      "|    reward          | -0.046243265 |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 196         |\n",
      "|    fps             | 28          |\n",
      "|    time_elapsed    | 576         |\n",
      "|    total_timesteps | 16464       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -192        |\n",
      "|    critic_loss     | 543         |\n",
      "|    ent_coef        | 0.0206      |\n",
      "|    ent_coef_loss   | -1.59e+03   |\n",
      "|    learning_rate   | 0.0001      |\n",
      "|    n_updates       | 16363       |\n",
      "|    reward          | -0.13354604 |\n",
      "------------------------------------\n",
      "day: 83, episode: 1410\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 949044.68\n",
      "total_reward: -50955.32\n",
      "total_cost: 8964.08\n",
      "total_trades: 14984\n",
      "Sharpe: -1.184\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 200         |\n",
      "|    fps             | 28          |\n",
      "|    time_elapsed    | 587         |\n",
      "|    total_timesteps | 16800       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -183        |\n",
      "|    critic_loss     | 1.28        |\n",
      "|    ent_coef        | 0.0199      |\n",
      "|    ent_coef_loss   | -1.61e+03   |\n",
      "|    learning_rate   | 0.0001      |\n",
      "|    n_updates       | 16699       |\n",
      "|    reward          | -0.19174507 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 204         |\n",
      "|    fps             | 28          |\n",
      "|    time_elapsed    | 599         |\n",
      "|    total_timesteps | 17136       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -159        |\n",
      "|    critic_loss     | 1.42        |\n",
      "|    ent_coef        | 0.0192      |\n",
      "|    ent_coef_loss   | -1.63e+03   |\n",
      "|    learning_rate   | 0.0001      |\n",
      "|    n_updates       | 17035       |\n",
      "|    reward          | -0.19937858 |\n",
      "------------------------------------\n",
      "day: 83, episode: 1420\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 940772.46\n",
      "total_reward: -59227.54\n",
      "total_cost: 9095.82\n",
      "total_trades: 15251\n",
      "Sharpe: -1.395\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    episodes        | 208          |\n",
      "|    fps             | 28           |\n",
      "|    time_elapsed    | 611          |\n",
      "|    total_timesteps | 17472        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -175         |\n",
      "|    critic_loss     | 3.13         |\n",
      "|    ent_coef        | 0.0186       |\n",
      "|    ent_coef_loss   | -1.63e+03    |\n",
      "|    learning_rate   | 0.0001       |\n",
      "|    n_updates       | 17371        |\n",
      "|    reward          | -0.102517135 |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 212         |\n",
      "|    fps             | 28          |\n",
      "|    time_elapsed    | 623         |\n",
      "|    total_timesteps | 17808       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -168        |\n",
      "|    critic_loss     | 1.34        |\n",
      "|    ent_coef        | 0.018       |\n",
      "|    ent_coef_loss   | -1.65e+03   |\n",
      "|    learning_rate   | 0.0001      |\n",
      "|    n_updates       | 17707       |\n",
      "|    reward          | 0.024601337 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 216         |\n",
      "|    fps             | 28          |\n",
      "|    time_elapsed    | 634         |\n",
      "|    total_timesteps | 18144       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -145        |\n",
      "|    critic_loss     | 1.41        |\n",
      "|    ent_coef        | 0.0174      |\n",
      "|    ent_coef_loss   | -1.66e+03   |\n",
      "|    learning_rate   | 0.0001      |\n",
      "|    n_updates       | 18043       |\n",
      "|    reward          | -0.13686255 |\n",
      "------------------------------------\n",
      "day: 83, episode: 1430\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 983436.64\n",
      "total_reward: -16563.36\n",
      "total_cost: 10749.92\n",
      "total_trades: 15158\n",
      "Sharpe: -0.299\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 220        |\n",
      "|    fps             | 28         |\n",
      "|    time_elapsed    | 646        |\n",
      "|    total_timesteps | 18480      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -134       |\n",
      "|    critic_loss     | 7.27       |\n",
      "|    ent_coef        | 0.0168     |\n",
      "|    ent_coef_loss   | -1.67e+03  |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 18379      |\n",
      "|    reward          | 0.02994469 |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 224       |\n",
      "|    fps             | 28        |\n",
      "|    time_elapsed    | 657       |\n",
      "|    total_timesteps | 18816     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -146      |\n",
      "|    critic_loss     | 5.28      |\n",
      "|    ent_coef        | 0.0163    |\n",
      "|    ent_coef_loss   | -1.68e+03 |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 18715     |\n",
      "|    reward          | 0.0460815 |\n",
      "----------------------------------\n",
      "day: 83, episode: 1440\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 992103.56\n",
      "total_reward: -7896.44\n",
      "total_cost: 9205.22\n",
      "total_trades: 15044\n",
      "Sharpe: -0.138\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 228        |\n",
      "|    fps             | 28         |\n",
      "|    time_elapsed    | 669        |\n",
      "|    total_timesteps | 19152      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -133       |\n",
      "|    critic_loss     | 7.32       |\n",
      "|    ent_coef        | 0.0157     |\n",
      "|    ent_coef_loss   | -1.69e+03  |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 19051      |\n",
      "|    reward          | 0.08808711 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 232        |\n",
      "|    fps             | 28         |\n",
      "|    time_elapsed    | 681        |\n",
      "|    total_timesteps | 19488      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -137       |\n",
      "|    critic_loss     | 1.53       |\n",
      "|    ent_coef        | 0.0152     |\n",
      "|    ent_coef_loss   | -1.7e+03   |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 19387      |\n",
      "|    reward          | 0.20963652 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 236        |\n",
      "|    fps             | 28         |\n",
      "|    time_elapsed    | 693        |\n",
      "|    total_timesteps | 19824      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -143       |\n",
      "|    critic_loss     | 18.7       |\n",
      "|    ent_coef        | 0.0147     |\n",
      "|    ent_coef_loss   | -1.7e+03   |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 19723      |\n",
      "|    reward          | 0.28991494 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 1450\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1044293.27\n",
      "total_reward: 44293.27\n",
      "total_cost: 8389.51\n",
      "total_trades: 14784\n",
      "Sharpe: 1.048\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 240       |\n",
      "|    fps             | 28        |\n",
      "|    time_elapsed    | 705       |\n",
      "|    total_timesteps | 20160     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -124      |\n",
      "|    critic_loss     | 7.74      |\n",
      "|    ent_coef        | 0.0142    |\n",
      "|    ent_coef_loss   | -1.73e+03 |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 20059     |\n",
      "|    reward          | 0.501246  |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 244        |\n",
      "|    fps             | 28         |\n",
      "|    time_elapsed    | 716        |\n",
      "|    total_timesteps | 20496      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -115       |\n",
      "|    critic_loss     | 1.04       |\n",
      "|    ent_coef        | 0.0138     |\n",
      "|    ent_coef_loss   | -1.75e+03  |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 20395      |\n",
      "|    reward          | 0.30745596 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 1460\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1032390.31\n",
      "total_reward: 32390.31\n",
      "total_cost: 7561.34\n",
      "total_trades: 14453\n",
      "Sharpe: 0.805\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 248        |\n",
      "|    fps             | 28         |\n",
      "|    time_elapsed    | 728        |\n",
      "|    total_timesteps | 20832      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -109       |\n",
      "|    critic_loss     | 0.779      |\n",
      "|    ent_coef        | 0.0133     |\n",
      "|    ent_coef_loss   | -1.77e+03  |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 20731      |\n",
      "|    reward          | 0.33589333 |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 252       |\n",
      "|    fps             | 28        |\n",
      "|    time_elapsed    | 740       |\n",
      "|    total_timesteps | 21168     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -103      |\n",
      "|    critic_loss     | 0.401     |\n",
      "|    ent_coef        | 0.0129    |\n",
      "|    ent_coef_loss   | -1.78e+03 |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 21067     |\n",
      "|    reward          | 0.3831478 |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 256        |\n",
      "|    fps             | 28         |\n",
      "|    time_elapsed    | 752        |\n",
      "|    total_timesteps | 21504      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -98.5      |\n",
      "|    critic_loss     | 0.755      |\n",
      "|    ent_coef        | 0.0124     |\n",
      "|    ent_coef_loss   | -1.79e+03  |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 21403      |\n",
      "|    reward          | 0.59951776 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 1470\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1023873.88\n",
      "total_reward: 23873.88\n",
      "total_cost: 9659.43\n",
      "total_trades: 14593\n",
      "Sharpe: 0.600\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 260        |\n",
      "|    fps             | 28         |\n",
      "|    time_elapsed    | 764        |\n",
      "|    total_timesteps | 21840      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -98.9      |\n",
      "|    critic_loss     | 9.65       |\n",
      "|    ent_coef        | 0.012      |\n",
      "|    ent_coef_loss   | -1.79e+03  |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 21739      |\n",
      "|    reward          | 0.45591062 |\n",
      "-----------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 264         |\n",
      "|    fps             | 28          |\n",
      "|    time_elapsed    | 776         |\n",
      "|    total_timesteps | 22176       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -93.2       |\n",
      "|    critic_loss     | 0.704       |\n",
      "|    ent_coef        | 0.0116      |\n",
      "|    ent_coef_loss   | -1.82e+03   |\n",
      "|    learning_rate   | 0.0001      |\n",
      "|    n_updates       | 22075       |\n",
      "|    reward          | 0.058033116 |\n",
      "------------------------------------\n",
      "day: 83, episode: 1480\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1029356.44\n",
      "total_reward: 29356.44\n",
      "total_cost: 9815.55\n",
      "total_trades: 14993\n",
      "Sharpe: 0.739\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 268        |\n",
      "|    fps             | 28         |\n",
      "|    time_elapsed    | 787        |\n",
      "|    total_timesteps | 22512      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -95.8      |\n",
      "|    critic_loss     | 0.357      |\n",
      "|    ent_coef        | 0.0112     |\n",
      "|    ent_coef_loss   | -1.83e+03  |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 22411      |\n",
      "|    reward          | 0.33045697 |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 272       |\n",
      "|    fps             | 28        |\n",
      "|    time_elapsed    | 799       |\n",
      "|    total_timesteps | 22848     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -97.3     |\n",
      "|    critic_loss     | 1.85      |\n",
      "|    ent_coef        | 0.0109    |\n",
      "|    ent_coef_loss   | -1.84e+03 |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 22747     |\n",
      "|    reward          | 0.3849861 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 276       |\n",
      "|    fps             | 28        |\n",
      "|    time_elapsed    | 811       |\n",
      "|    total_timesteps | 23184     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -87.5     |\n",
      "|    critic_loss     | 69        |\n",
      "|    ent_coef        | 0.0105    |\n",
      "|    ent_coef_loss   | -1.86e+03 |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 23083     |\n",
      "|    reward          | 0.2777854 |\n",
      "----------------------------------\n",
      "day: 83, episode: 1490\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1038193.53\n",
      "total_reward: 38193.53\n",
      "total_cost: 8932.42\n",
      "total_trades: 14585\n",
      "Sharpe: 0.898\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 280        |\n",
      "|    fps             | 28         |\n",
      "|    time_elapsed    | 822        |\n",
      "|    total_timesteps | 23520      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -84.8      |\n",
      "|    critic_loss     | 0.693      |\n",
      "|    ent_coef        | 0.0102     |\n",
      "|    ent_coef_loss   | -1.87e+03  |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 23419      |\n",
      "|    reward          | 0.46002313 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 284        |\n",
      "|    fps             | 28         |\n",
      "|    time_elapsed    | 834        |\n",
      "|    total_timesteps | 23856      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -81.7      |\n",
      "|    critic_loss     | 1          |\n",
      "|    ent_coef        | 0.00983    |\n",
      "|    ent_coef_loss   | -1.88e+03  |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 23755      |\n",
      "|    reward          | 0.55186903 |\n",
      "-----------------------------------\n",
      "day: 83, episode: 1500\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1033813.79\n",
      "total_reward: 33813.79\n",
      "total_cost: 7936.54\n",
      "total_trades: 14485\n",
      "Sharpe: 0.826\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 288        |\n",
      "|    fps             | 28         |\n",
      "|    time_elapsed    | 845        |\n",
      "|    total_timesteps | 24192      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -79        |\n",
      "|    critic_loss     | 0.755      |\n",
      "|    ent_coef        | 0.00951    |\n",
      "|    ent_coef_loss   | -1.89e+03  |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 24091      |\n",
      "|    reward          | 0.39416012 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 292        |\n",
      "|    fps             | 28         |\n",
      "|    time_elapsed    | 857        |\n",
      "|    total_timesteps | 24528      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -75.6      |\n",
      "|    critic_loss     | 0.293      |\n",
      "|    ent_coef        | 0.00919    |\n",
      "|    ent_coef_loss   | -1.91e+03  |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 24427      |\n",
      "|    reward          | 0.21132433 |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 296       |\n",
      "|    fps             | 28        |\n",
      "|    time_elapsed    | 868       |\n",
      "|    total_timesteps | 24864     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -78.3     |\n",
      "|    critic_loss     | 0.422     |\n",
      "|    ent_coef        | 0.00889   |\n",
      "|    ent_coef_loss   | -1.92e+03 |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 24763     |\n",
      "|    reward          | 0.2885431 |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_sac = agent.train_model(model=model_sac,\n",
    "                             tb_log_name='sac',\n",
    "                             total_timesteps=25000) if if_using_sac else None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T10:12:24.720853600Z",
     "start_time": "2024-02-26T09:57:50.868474300Z"
    }
   },
   "id": "10bbf370223fae7d",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_risk_indicator = processed_full[(processed_full.date<TRAIN_END_DATE) & (processed_full.date>=TRAIN_START_DATE)]\n",
    "insample_risk_indicator = data_risk_indicator.drop_duplicates(subset=['date'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T10:12:24.901637600Z",
     "start_time": "2024-02-26T10:12:24.757513400Z"
    }
   },
   "id": "b458c64061f8442e",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "turbulence_threshold = np.quantile(insample_risk_indicator.turbulence.values,0.75)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T10:12:24.945849500Z",
     "start_time": "2024-02-26T10:12:24.905751Z"
    }
   },
   "id": "b055191186b86e1f",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "count    84.000000\nmean      3.968300\nstd       3.782166\nmin       0.000000\n25%       0.000000\n50%       3.294360\n75%       5.829139\nmax      20.738782\nName: turbulence, dtype: float64"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.turbulence.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T10:12:25.028966300Z",
     "start_time": "2024-02-26T10:12:24.932723200Z"
    }
   },
   "id": "e6ae9c42c3ba08a4",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "5.829138720757349"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turbulence_threshold"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T10:12:25.032228800Z",
     "start_time": "2024-02-26T10:12:24.998100100Z"
    }
   },
   "id": "3addbb6cf99c205b",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold=turbulence_threshold, risk_indicator_col='turbulence', **env_kwargs)\n",
    "# env_trade, obs_trade = e_trade_gym.get_sb_env()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T10:12:25.089963300Z",
     "start_time": "2024-02-26T10:12:25.027914900Z"
    }
   },
   "id": "c5812be064729a61",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "trained_moedl = trained_a2c\n",
    "df_account_value_a2c, df_actions_a2c = DRLAgent.DRL_prediction(\n",
    "    model=trained_moedl, \n",
    "    environment = e_trade_gym)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T10:12:25.602710900Z",
     "start_time": "2024-02-26T10:12:25.072336700Z"
    }
   },
   "id": "52b2a3d5cf292634",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "trained_moedl = trained_ddpg\n",
    "df_account_value_ddpg, df_actions_ddpg = DRLAgent.DRL_prediction(\n",
    "    model=trained_moedl, \n",
    "    environment = e_trade_gym)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T10:12:26.077457Z",
     "start_time": "2024-02-26T10:12:25.601359900Z"
    }
   },
   "id": "d69442844a38d9be",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "trained_moedl = trained_ppo\n",
    "df_account_value_ppo, df_actions_ppo = DRLAgent.DRL_prediction(\n",
    "    model=trained_moedl, \n",
    "    environment = e_trade_gym)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T10:12:26.605885700Z",
     "start_time": "2024-02-26T10:12:26.079456600Z"
    }
   },
   "id": "138d0c28790911ca",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "trained_moedl = trained_td3\n",
    "df_account_value_td3, df_actions_td3 = DRLAgent.DRL_prediction(\n",
    "    model=trained_moedl, \n",
    "    environment = e_trade_gym)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T10:12:27.261886600Z",
     "start_time": "2024-02-26T10:12:26.617888500Z"
    }
   },
   "id": "628334a499155432",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "trained_moedl = trained_sac\n",
    "df_account_value_sac, df_actions_sac = DRLAgent.DRL_prediction(\n",
    "    model=trained_moedl, \n",
    "    environment = e_trade_gym)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T10:12:27.959858600Z",
     "start_time": "2024-02-26T10:12:27.251884600Z"
    }
   },
   "id": "2d5e29bc25265a24",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(60, 2)"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value_a2c.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T10:12:28.017925900Z",
     "start_time": "2024-02-26T10:12:27.961858500Z"
    }
   },
   "id": "a9a28015c672779c",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def process_df_for_mvo(df):\n",
    "  df = df.sort_values(['date','tic'],ignore_index=True)[['date','tic','close']]\n",
    "  fst = df\n",
    "  fst = fst.iloc[0:stock_dimension, :]\n",
    "  tic = fst['tic'].tolist()\n",
    "\n",
    "  mvo = pd.DataFrame()\n",
    "\n",
    "  for k in range(len(tic)):\n",
    "    mvo[tic[k]] = 0\n",
    "\n",
    "  for i in range(df.shape[0]//stock_dimension):\n",
    "    n = df\n",
    "    n = n.iloc[i * stock_dimension:(i+1) * stock_dimension, :]\n",
    "    date = n['date'][i*stock_dimension]\n",
    "    mvo.loc[date] = n['close'].tolist()\n",
    "  \n",
    "  return mvo"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T10:12:28.039110400Z",
     "start_time": "2024-02-26T10:12:27.990962400Z"
    }
   },
   "id": "8c3ce9732a5aa54f",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Codes in this section partially refer to Dr G A Vijayalakshmi Pai\n",
    "\n",
    "# https://www.kaggle.com/code/vijipai/lesson-5-mean-variance-optimization-of-portfolios/notebook\n",
    "\n",
    "def StockReturnsComputing(StockPrice, Rows, Columns): \n",
    "  import numpy as np \n",
    "  StockReturn = np.zeros([Rows-1, Columns]) \n",
    "  for j in range(Columns):        # j: Assets \n",
    "    for i in range(Rows-1):     # i: Daily Prices \n",
    "      StockReturn[i,j]=((StockPrice[i+1, j]-StockPrice[i,j])/StockPrice[i,j])* 100 \n",
    "      \n",
    "  return StockReturn"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T10:12:28.099468800Z",
     "start_time": "2024-02-26T10:12:28.025293300Z"
    }
   },
   "id": "1c5b7765cc8767c8",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_mvo = data_split(processed_full, TRAIN_START_DATE,TRAIN_END_DATE).reset_index()\n",
    "trade_mvo = data_split(processed_full, TRADE_START_DATE,TRADE_END_DATE).reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T10:12:28.347972300Z",
     "start_time": "2024-02-26T10:12:28.057945Z"
    }
   },
   "id": "70af2852d5a315bf",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n",
      "C:\\Users\\胡逸凡\\AppData\\Local\\Temp\\ipykernel_12124\\2297495636.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mvo[tic[k]] = 0\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[ 7.03      ,  2.82      ,  5.67052632, ..., 46.36058824,\n        35.439     , 50.72315789],\n       [ 7.01777778,  2.81      ,  5.65      , ..., 44.92      ,\n        35.439     , 50.82947368],\n       [ 7.02      ,  2.8       ,  5.61      , ..., 45.4775    ,\n        35.12      , 54.2       ],\n       ...,\n       [ 6.600625  ,  2.66      ,  5.76      , ..., 44.699     ,\n        27.20714286, 51.91      ],\n       [ 6.68      ,  2.68      ,  5.67      , ..., 45.55      ,\n        27.8625    , 53.13      ],\n       [ 6.61736842,  2.69      ,  5.62444444, ..., 45.341     ,\n        27.92      , 53.02      ]])"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StockData = process_df_for_mvo(train_mvo)\n",
    "TradeData = process_df_for_mvo(trade_mvo)\n",
    "\n",
    "TradeData.to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T10:12:28.860746500Z",
     "start_time": "2024-02-26T10:12:28.356375600Z"
    }
   },
   "id": "9c08253199bed780",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean returns of assets in k-portfolio 1\n",
      " [-0.023 -0.081  0.005  0.004 -0.021  0.06   0.008  0.024 -0.066  0.075\n",
      "  0.046  0.017 -0.064 -0.016  0.021  0.117  0.008  0.08  -0.034 -0.181\n",
      " -0.042 -0.163 -0.078  0.059 -0.189  0.025  0.04   0.037 -0.102 -0.119\n",
      " -0.087  0.057  0.053  0.097 -0.112 -0.106 -0.209  0.151  0.103 -0.104\n",
      " -0.065  0.004  0.097 -0.11  -0.315 -0.093  0.021 -0.014  0.055  0.005\n",
      " -0.089 -0.35  -0.111  0.109 -0.202  0.144  0.145 -0.036 -0.153 -0.006\n",
      " -0.064  0.099  0.04   0.001 -0.134 -0.095 -0.143  0.121 -0.171  0.448\n",
      "  0.133 -0.077 -0.083 -0.044  0.063 -0.11  -0.017 -0.096 -0.16  -0.062\n",
      "  0.087  0.05   0.046  0.165 -0.097 -0.076  0.026 -0.023  0.125 -0.277\n",
      "  0.064  0.118 -0.221 -0.19  -0.317  0.101 -0.102  0.218 -0.015 -0.032\n",
      "  0.077 -0.148  0.044  0.041  0.121 -0.127 -0.092  0.143 -0.063 -0.091\n",
      " -0.286 -0.145 -0.002 -0.116 -0.039 -0.038 -0.155  0.221 -0.15   0.105\n",
      " -0.09   0.176 -0.358  0.019 -0.038 -0.052  0.025  0.118 -0.018  0.071\n",
      "  0.035  0.142  0.007  0.079  0.007  0.097  0.055 -0.064  0.016 -0.013\n",
      " -0.012  0.003  0.002  0.006 -0.012  0.135  0.007 -0.015  0.054 -0.109\n",
      " -0.027 -0.007  0.034  0.06  -0.032 -0.047  0.048 -0.266 -0.164 -0.198\n",
      " -0.033 -0.037  0.054 -0.09  -0.198 -0.023  0.191 -0.049  0.458  0.178\n",
      " -0.074 -0.023  0.049  0.138  0.066 -0.064 -0.002  0.089  0.128 -0.054\n",
      " -0.004 -0.134 -0.025  0.058 -0.14   0.017  0.    -0.044  0.207 -0.509\n",
      "  0.35  -0.321 -0.028  0.095  0.03  -0.305 -0.174 -0.21  -0.051 -0.253\n",
      " -0.202 -0.04  -0.531 -0.123 -0.053 -0.369 -0.488 -0.236 -0.115 -0.116\n",
      " -0.547  0.11  -0.709 -0.663 -0.107 -0.405  0.028 -0.118 -0.236 -0.576\n",
      " -0.546 -0.113  0.05  -0.177 -0.115 -0.311 -0.596 -0.016 -0.196 -0.456\n",
      " -0.36  -0.712 -0.275 -0.108 -0.092 -0.398 -0.047  0.027 -0.024 -0.244\n",
      " -0.171 -0.247 -0.583 -0.06  -0.2   -0.013  0.027 -0.362 -0.123  0.446\n",
      " -0.265 -0.055 -0.298 -0.066 -0.049 -0.826  0.022 -0.051]\n",
      "Variance-Covariance matrix of returns\n",
      " [[ 0.974  0.312  0.786 ...  0.418  0.363  0.492]\n",
      " [ 0.312  1.016  0.633 ... -0.2    0.161  0.246]\n",
      " [ 0.786  0.633  1.713 ...  0.379  0.504  0.602]\n",
      " ...\n",
      " [ 0.418 -0.2    0.379 ... 15.69   0.04   0.837]\n",
      " [ 0.363  0.161  0.504 ...  0.04   2.476  0.8  ]\n",
      " [ 0.492  0.246  0.602 ...  0.837  0.8    4.647]]\n"
     ]
    }
   ],
   "source": [
    "#compute asset returns\n",
    "arStockPrices = np.asarray(StockData)\n",
    "[Rows, Cols]=arStockPrices.shape\n",
    "arReturns = StockReturnsComputing(arStockPrices, Rows, Cols)\n",
    "\n",
    "#compute mean returns and variance covariance matrix of returns\n",
    "meanReturns = np.mean(arReturns, axis = 0)\n",
    "covReturns = np.cov(arReturns, rowvar=False)\n",
    " \n",
    "#set precision for printing results\n",
    "np.set_printoptions(precision=3, suppress = True)\n",
    "\n",
    "#display mean returns and variance-covariance matrix of returns\n",
    "print('Mean returns of assets in k-portfolio 1\\n', meanReturns)\n",
    "print('Variance-Covariance matrix of returns\\n', covReturns)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T10:12:28.992399200Z",
     "start_time": "2024-02-26T10:12:28.863864900Z"
    }
   },
   "id": "b9a35fb7c0a96b6f",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\lib\\site-packages\\cvxpy-1.4.1-py3.10-win-amd64.egg\\cvxpy\\reductions\\solvers\\solving_chain.py:336: FutureWarning: \n",
      "    Your problem is being solved with the ECOS solver by default. Starting in \n",
      "    CVXPY 1.5.0, Clarabel will be used as the default solver instead. To continue \n",
      "    using ECOS, specify the ECOS solver explicitly using the ``solver=cp.ECOS`` \n",
      "    argument to the ``problem.solve`` method.\n",
      "    \n",
      "  warnings.warn(ECOS_DEPRECATION_MSG, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([     0.,      0.,      0.,      0.,      0.,      0.,      0.,\n            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n            0.,      0.,      0.,      0.,      0.,      0., 500000.,\n            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n       500000.,      0.,      0.,      0.,      0.,      0.,      0.,\n            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n            0.,      0.,      0.,      0.,      0.,      0.,      0.,\n            0.,      0.,      0.,      0.,      0.,      0.])"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "\n",
    "ef_mean = EfficientFrontier(meanReturns, covReturns, weight_bounds=(0, 0.5))\n",
    "# raw_weights_mean = ef_mean.max_sharpe()\n",
    "raw_weights_mean = ef_mean._max_return()\n",
    "cleaned_weights_mean = ef_mean.clean_weights()\n",
    "mvo_weights = np.array([1000000 * cleaned_weights_mean[i] for i in range(stock_dimension)])\n",
    "mvo_weights"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T10:12:29.913837300Z",
     "start_time": "2024-02-26T10:12:28.924383700Z"
    }
   },
   "id": "bba00a20861e8a7d",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([    0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   , 26554.783,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n        3290.756,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ,\n           0.   ,     0.   ,     0.   ,     0.   ,     0.   ,     0.   ])"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LastPrice = np.array([1/p for p in StockData.tail(1).to_numpy()[0]])\n",
    "Initial_Portfolio = np.multiply(mvo_weights, LastPrice)\n",
    "Initial_Portfolio"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T10:12:30.006337Z",
     "start_time": "2024-02-26T10:12:29.905577Z"
    }
   },
   "id": "9f9a734af901443f",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "Portfolio_Assets = TradeData @ Initial_Portfolio\n",
    "MVO_result = pd.DataFrame(Portfolio_Assets, columns=[\"Mean Var\"])\n",
    "# MVO_result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T10:12:30.049853200Z",
     "start_time": "2024-02-26T10:12:29.931211500Z"
    }
   },
   "id": "f898498a20167363",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       a2c            ddpg             td3             ppo  \\\n",
      "date                                                                         \n",
      "2023-10-09  1000000.000000  1000000.000000  1000000.000000  1000000.000000   \n",
      "2023-10-10   998791.609048   998512.070767   995672.211883   999230.126125   \n",
      "2023-10-11   998614.109254   998214.936231   995154.529566   999114.127260   \n",
      "2023-10-12   999107.426919   999752.410692   997971.709514   999299.142384   \n",
      "2023-10-13   998929.053007   999452.768785   997447.941688   999182.303546   \n",
      "\n",
      "                       sac      Mean Var  \n",
      "date                                      \n",
      "2023-10-09  1000000.000000  1.018310e+06  \n",
      "2023-10-10   998847.719450  1.000857e+06  \n",
      "2023-10-11   998690.895793  9.936863e+05  \n",
      "2023-10-12   999554.249626  9.843008e+05  \n",
      "2023-10-13   999395.274123  9.849446e+05  \n"
     ]
    }
   ],
   "source": [
    "if if_using_a2c:\n",
    "    df_result_a2c = df_account_value_a2c.set_index(df_account_value_a2c.columns[0])\n",
    "    df_result_a2c.rename(columns = {'account_value':'a2c'}, inplace = True)\n",
    "if if_using_ddpg:\n",
    "    df_result_ddpg = df_account_value_ddpg.set_index(df_account_value_ddpg.columns[0])\n",
    "    df_result_ddpg.rename(columns = {'account_value':'ddpg'}, inplace = True)\n",
    "if if_using_td3:\n",
    "    df_result_td3 = df_account_value_td3.set_index(df_account_value_td3.columns[0])\n",
    "    df_result_td3.rename(columns = {'account_value':'td3'}, inplace = True)\n",
    "if if_using_ppo:\n",
    "    df_result_ppo = df_account_value_ppo.set_index(df_account_value_ppo.columns[0])\n",
    "    df_result_ppo.rename(columns = {'account_value':'ppo'}, inplace = True)\n",
    "if if_using_sac:\n",
    "   df_result_sac = df_account_value_sac.set_index(df_account_value_sac.columns[0])\n",
    "   df_result_sac.rename(columns = {'account_value':'sac'}, inplace = True)\n",
    "\n",
    "\n",
    "result = pd.DataFrame()\n",
    "if if_using_a2c:\n",
    "    result = pd.merge(result, df_result_a2c, how='outer', left_index=True, right_index=True)\n",
    "if if_using_ddpg:\n",
    "    result = pd.merge(result, df_result_ddpg, how='outer', left_index=True, right_index=True)\n",
    "if if_using_td3:\n",
    "    result = pd.merge(result, df_result_td3, how='outer', left_index=True, right_index=True)\n",
    "if if_using_ppo:\n",
    "    result = pd.merge(result, df_result_ppo, how='outer', left_index=True, right_index=True)\n",
    "if if_using_sac:\n",
    "    result = pd.merge(result, df_result_sac, how='outer', left_index=True, right_index=True)\n",
    "result = pd.merge(result, MVO_result, how='outer', left_index=True, right_index=True)\n",
    "print(result.head())\n",
    "# result.columns = ['a2c', 'ddpg', 'td3', 'ppo', 'sac', 'mean var', 'dji']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T10:12:30.098950800Z",
     "start_time": "2024-02-26T10:12:29.966802800Z"
    }
   },
   "id": "b5cac20134c79eb3",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                 a2c      ddpg       td3       ppo       sac  Mean Var\ndate                                                                  \n2023-10-09  1.000000  1.000000  1.000000  1.000000  1.000000  1.018310\n2023-10-10  0.998792  0.998512  0.995672  0.999230  0.998848  1.000857\n2023-10-11  0.998614  0.998215  0.995155  0.999114  0.998691  0.993686\n2023-10-12  0.999107  0.999752  0.997972  0.999299  0.999554  0.984301\n2023-10-13  0.998929  0.999453  0.997448  0.999182  0.999395  0.984945\n2023-10-16  0.997056  0.995048  0.991096  0.997801  0.996864  0.999165\n2023-10-17  0.996882  0.994754  0.990586  0.997687  0.996705  1.007111\n2023-10-18  0.996882  0.994754  0.990586  0.997687  0.996705  1.003967\n2023-10-19  0.996882  0.994754  0.990586  0.997687  0.996705  0.982211\n2023-10-20  0.996882  0.994754  0.990586  0.997687  0.996705  0.975533\n2023-10-23  0.993070  0.988067  0.982055  0.996729  0.994524  0.959342\n2023-10-24  0.992905  0.987789  0.981572  0.996622  0.994357  0.956188\n2023-10-25  0.992905  0.987789  0.981572  0.996622  0.994357  0.938319\n2023-10-26  0.992905  0.987789  0.981572  0.996622  0.994357  0.909919\n2023-10-27  0.995068  0.993979  0.986348  0.997172  0.996672  0.909989\n2023-10-30  0.994899  0.993689  0.985855  0.997061  0.996499  0.904423\n2023-10-31  0.994899  0.993689  0.985855  0.997061  0.996499  0.913810\n2023-11-01  0.993919  0.991689  0.992898  1.001218  0.999900  0.904829\n2023-11-02  0.990135  0.982678  0.984824  1.000134  0.997196  0.892339\n2023-11-03  0.996219  0.997847  1.003202  1.006123  1.005661  0.905536\n2023-11-06  0.995707  0.996962  1.002199  1.005770  1.005101  0.906244\n2023-11-07  0.995707  0.996962  1.002199  1.005770  1.005101  0.896197\n2023-11-08  0.995477  0.997648  1.003163  1.006035  1.005218  0.890837\n2023-11-09  0.995419  0.997279  1.001162  1.005727  1.004860  0.905659\n2023-11-10  0.993906  0.999988  0.995970  1.002737  1.001547  0.906451\n2023-11-13  0.994565  0.998038  0.995138  0.999464  0.999277  0.895410\n2023-11-14  0.995397  0.998555  0.996021  0.999815  0.998779  0.894124\n2023-11-15  1.001543  1.001950  1.000074  1.003579  1.002832  0.904579\n2023-11-16  0.991063  0.989185  0.990461  0.996730  0.993677  0.903669\n2023-11-17  0.994329  0.980947  0.992120  0.994920  0.984324  0.912455\n2023-11-20  0.993335  0.979966  0.991128  0.993987  0.983340  0.908965\n2023-11-21  0.992627  0.978915  0.990974  0.995061  0.984180  0.914080\n2023-11-22  0.988006  0.969995  0.978927  0.993557  0.980716  0.909492\n2023-11-23  0.992887  0.978180  0.984312  0.994953  0.982972  0.939767\n2023-11-24  0.984195  0.967543  0.972847  0.991312  0.976795  0.948159\n2023-11-27  0.984545  0.964967  0.969544  0.987534  0.972483  0.964497\n2023-11-28  0.983686  0.964002  0.968575  0.986952  0.971536  0.950482\n2023-11-29  0.983716  0.963612  0.965868  0.986938  0.970877  0.964543\n2023-11-30  0.983545  0.963322  0.965365  0.986823  0.970712  0.959994\n2023-12-01  0.982870  0.961085  0.962161  0.985125  0.969140  0.964310\n2023-12-04  0.982699  0.960798  0.961659  0.985011  0.968972  0.969424\n2023-12-05  0.982699  0.960798  0.961659  0.985011  0.968972  0.942160\n2023-12-06  0.982699  0.960798  0.961659  0.985011  0.968972  0.929582\n2023-12-07  0.982636  0.959145  0.959470  0.984746  0.968191  0.930242\n2023-12-08  0.982470  0.958867  0.958983  0.984636  0.968036  0.906393\n2023-12-11  0.984259  0.961341  0.961938  0.984094  0.968233  0.949765\n2023-12-12  0.984089  0.961058  0.961443  0.983980  0.968075  0.957548\n2023-12-13  0.981061  0.957954  0.952901  0.981144  0.964788  0.948730\n2023-12-14  0.980894  0.957674  0.952413  0.981036  0.964637  0.958100\n2023-12-15  0.979370  0.954958  0.949250  0.980868  0.963878  0.939669\n2023-12-18  0.975625  0.947206  0.943937  0.982323  0.962786  0.945398\n2023-12-19  0.975298  0.946659  0.942993  0.982104  0.962456  0.932332\n2023-12-20  0.972542  0.943056  0.935203  0.980208  0.959929  0.921403\n2023-12-21  0.972381  0.942787  0.934728  0.980099  0.959761  0.916956\n2023-12-22  0.972381  0.942787  0.934728  0.980099  0.959761  0.917415\n2023-12-25  0.972381  0.942787  0.934728  0.980099  0.959761  0.909602\n2023-12-26  0.970226  0.939186  0.930754  0.979564  0.958438  0.891284\n2023-12-27  0.971734  0.942917  0.931074  0.979540  0.958349  0.906690\n2023-12-28  0.971412  0.942377  0.930142  0.979322  0.957978  0.887815\n2023-12-29  0.971412  0.942377  0.930142  0.979322  0.957978  0.896761",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>a2c</th>\n      <th>ddpg</th>\n      <th>td3</th>\n      <th>ppo</th>\n      <th>sac</th>\n      <th>Mean Var</th>\n    </tr>\n    <tr>\n      <th>date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2023-10-09</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.018310</td>\n    </tr>\n    <tr>\n      <th>2023-10-10</th>\n      <td>0.998792</td>\n      <td>0.998512</td>\n      <td>0.995672</td>\n      <td>0.999230</td>\n      <td>0.998848</td>\n      <td>1.000857</td>\n    </tr>\n    <tr>\n      <th>2023-10-11</th>\n      <td>0.998614</td>\n      <td>0.998215</td>\n      <td>0.995155</td>\n      <td>0.999114</td>\n      <td>0.998691</td>\n      <td>0.993686</td>\n    </tr>\n    <tr>\n      <th>2023-10-12</th>\n      <td>0.999107</td>\n      <td>0.999752</td>\n      <td>0.997972</td>\n      <td>0.999299</td>\n      <td>0.999554</td>\n      <td>0.984301</td>\n    </tr>\n    <tr>\n      <th>2023-10-13</th>\n      <td>0.998929</td>\n      <td>0.999453</td>\n      <td>0.997448</td>\n      <td>0.999182</td>\n      <td>0.999395</td>\n      <td>0.984945</td>\n    </tr>\n    <tr>\n      <th>2023-10-16</th>\n      <td>0.997056</td>\n      <td>0.995048</td>\n      <td>0.991096</td>\n      <td>0.997801</td>\n      <td>0.996864</td>\n      <td>0.999165</td>\n    </tr>\n    <tr>\n      <th>2023-10-17</th>\n      <td>0.996882</td>\n      <td>0.994754</td>\n      <td>0.990586</td>\n      <td>0.997687</td>\n      <td>0.996705</td>\n      <td>1.007111</td>\n    </tr>\n    <tr>\n      <th>2023-10-18</th>\n      <td>0.996882</td>\n      <td>0.994754</td>\n      <td>0.990586</td>\n      <td>0.997687</td>\n      <td>0.996705</td>\n      <td>1.003967</td>\n    </tr>\n    <tr>\n      <th>2023-10-19</th>\n      <td>0.996882</td>\n      <td>0.994754</td>\n      <td>0.990586</td>\n      <td>0.997687</td>\n      <td>0.996705</td>\n      <td>0.982211</td>\n    </tr>\n    <tr>\n      <th>2023-10-20</th>\n      <td>0.996882</td>\n      <td>0.994754</td>\n      <td>0.990586</td>\n      <td>0.997687</td>\n      <td>0.996705</td>\n      <td>0.975533</td>\n    </tr>\n    <tr>\n      <th>2023-10-23</th>\n      <td>0.993070</td>\n      <td>0.988067</td>\n      <td>0.982055</td>\n      <td>0.996729</td>\n      <td>0.994524</td>\n      <td>0.959342</td>\n    </tr>\n    <tr>\n      <th>2023-10-24</th>\n      <td>0.992905</td>\n      <td>0.987789</td>\n      <td>0.981572</td>\n      <td>0.996622</td>\n      <td>0.994357</td>\n      <td>0.956188</td>\n    </tr>\n    <tr>\n      <th>2023-10-25</th>\n      <td>0.992905</td>\n      <td>0.987789</td>\n      <td>0.981572</td>\n      <td>0.996622</td>\n      <td>0.994357</td>\n      <td>0.938319</td>\n    </tr>\n    <tr>\n      <th>2023-10-26</th>\n      <td>0.992905</td>\n      <td>0.987789</td>\n      <td>0.981572</td>\n      <td>0.996622</td>\n      <td>0.994357</td>\n      <td>0.909919</td>\n    </tr>\n    <tr>\n      <th>2023-10-27</th>\n      <td>0.995068</td>\n      <td>0.993979</td>\n      <td>0.986348</td>\n      <td>0.997172</td>\n      <td>0.996672</td>\n      <td>0.909989</td>\n    </tr>\n    <tr>\n      <th>2023-10-30</th>\n      <td>0.994899</td>\n      <td>0.993689</td>\n      <td>0.985855</td>\n      <td>0.997061</td>\n      <td>0.996499</td>\n      <td>0.904423</td>\n    </tr>\n    <tr>\n      <th>2023-10-31</th>\n      <td>0.994899</td>\n      <td>0.993689</td>\n      <td>0.985855</td>\n      <td>0.997061</td>\n      <td>0.996499</td>\n      <td>0.913810</td>\n    </tr>\n    <tr>\n      <th>2023-11-01</th>\n      <td>0.993919</td>\n      <td>0.991689</td>\n      <td>0.992898</td>\n      <td>1.001218</td>\n      <td>0.999900</td>\n      <td>0.904829</td>\n    </tr>\n    <tr>\n      <th>2023-11-02</th>\n      <td>0.990135</td>\n      <td>0.982678</td>\n      <td>0.984824</td>\n      <td>1.000134</td>\n      <td>0.997196</td>\n      <td>0.892339</td>\n    </tr>\n    <tr>\n      <th>2023-11-03</th>\n      <td>0.996219</td>\n      <td>0.997847</td>\n      <td>1.003202</td>\n      <td>1.006123</td>\n      <td>1.005661</td>\n      <td>0.905536</td>\n    </tr>\n    <tr>\n      <th>2023-11-06</th>\n      <td>0.995707</td>\n      <td>0.996962</td>\n      <td>1.002199</td>\n      <td>1.005770</td>\n      <td>1.005101</td>\n      <td>0.906244</td>\n    </tr>\n    <tr>\n      <th>2023-11-07</th>\n      <td>0.995707</td>\n      <td>0.996962</td>\n      <td>1.002199</td>\n      <td>1.005770</td>\n      <td>1.005101</td>\n      <td>0.896197</td>\n    </tr>\n    <tr>\n      <th>2023-11-08</th>\n      <td>0.995477</td>\n      <td>0.997648</td>\n      <td>1.003163</td>\n      <td>1.006035</td>\n      <td>1.005218</td>\n      <td>0.890837</td>\n    </tr>\n    <tr>\n      <th>2023-11-09</th>\n      <td>0.995419</td>\n      <td>0.997279</td>\n      <td>1.001162</td>\n      <td>1.005727</td>\n      <td>1.004860</td>\n      <td>0.905659</td>\n    </tr>\n    <tr>\n      <th>2023-11-10</th>\n      <td>0.993906</td>\n      <td>0.999988</td>\n      <td>0.995970</td>\n      <td>1.002737</td>\n      <td>1.001547</td>\n      <td>0.906451</td>\n    </tr>\n    <tr>\n      <th>2023-11-13</th>\n      <td>0.994565</td>\n      <td>0.998038</td>\n      <td>0.995138</td>\n      <td>0.999464</td>\n      <td>0.999277</td>\n      <td>0.895410</td>\n    </tr>\n    <tr>\n      <th>2023-11-14</th>\n      <td>0.995397</td>\n      <td>0.998555</td>\n      <td>0.996021</td>\n      <td>0.999815</td>\n      <td>0.998779</td>\n      <td>0.894124</td>\n    </tr>\n    <tr>\n      <th>2023-11-15</th>\n      <td>1.001543</td>\n      <td>1.001950</td>\n      <td>1.000074</td>\n      <td>1.003579</td>\n      <td>1.002832</td>\n      <td>0.904579</td>\n    </tr>\n    <tr>\n      <th>2023-11-16</th>\n      <td>0.991063</td>\n      <td>0.989185</td>\n      <td>0.990461</td>\n      <td>0.996730</td>\n      <td>0.993677</td>\n      <td>0.903669</td>\n    </tr>\n    <tr>\n      <th>2023-11-17</th>\n      <td>0.994329</td>\n      <td>0.980947</td>\n      <td>0.992120</td>\n      <td>0.994920</td>\n      <td>0.984324</td>\n      <td>0.912455</td>\n    </tr>\n    <tr>\n      <th>2023-11-20</th>\n      <td>0.993335</td>\n      <td>0.979966</td>\n      <td>0.991128</td>\n      <td>0.993987</td>\n      <td>0.983340</td>\n      <td>0.908965</td>\n    </tr>\n    <tr>\n      <th>2023-11-21</th>\n      <td>0.992627</td>\n      <td>0.978915</td>\n      <td>0.990974</td>\n      <td>0.995061</td>\n      <td>0.984180</td>\n      <td>0.914080</td>\n    </tr>\n    <tr>\n      <th>2023-11-22</th>\n      <td>0.988006</td>\n      <td>0.969995</td>\n      <td>0.978927</td>\n      <td>0.993557</td>\n      <td>0.980716</td>\n      <td>0.909492</td>\n    </tr>\n    <tr>\n      <th>2023-11-23</th>\n      <td>0.992887</td>\n      <td>0.978180</td>\n      <td>0.984312</td>\n      <td>0.994953</td>\n      <td>0.982972</td>\n      <td>0.939767</td>\n    </tr>\n    <tr>\n      <th>2023-11-24</th>\n      <td>0.984195</td>\n      <td>0.967543</td>\n      <td>0.972847</td>\n      <td>0.991312</td>\n      <td>0.976795</td>\n      <td>0.948159</td>\n    </tr>\n    <tr>\n      <th>2023-11-27</th>\n      <td>0.984545</td>\n      <td>0.964967</td>\n      <td>0.969544</td>\n      <td>0.987534</td>\n      <td>0.972483</td>\n      <td>0.964497</td>\n    </tr>\n    <tr>\n      <th>2023-11-28</th>\n      <td>0.983686</td>\n      <td>0.964002</td>\n      <td>0.968575</td>\n      <td>0.986952</td>\n      <td>0.971536</td>\n      <td>0.950482</td>\n    </tr>\n    <tr>\n      <th>2023-11-29</th>\n      <td>0.983716</td>\n      <td>0.963612</td>\n      <td>0.965868</td>\n      <td>0.986938</td>\n      <td>0.970877</td>\n      <td>0.964543</td>\n    </tr>\n    <tr>\n      <th>2023-11-30</th>\n      <td>0.983545</td>\n      <td>0.963322</td>\n      <td>0.965365</td>\n      <td>0.986823</td>\n      <td>0.970712</td>\n      <td>0.959994</td>\n    </tr>\n    <tr>\n      <th>2023-12-01</th>\n      <td>0.982870</td>\n      <td>0.961085</td>\n      <td>0.962161</td>\n      <td>0.985125</td>\n      <td>0.969140</td>\n      <td>0.964310</td>\n    </tr>\n    <tr>\n      <th>2023-12-04</th>\n      <td>0.982699</td>\n      <td>0.960798</td>\n      <td>0.961659</td>\n      <td>0.985011</td>\n      <td>0.968972</td>\n      <td>0.969424</td>\n    </tr>\n    <tr>\n      <th>2023-12-05</th>\n      <td>0.982699</td>\n      <td>0.960798</td>\n      <td>0.961659</td>\n      <td>0.985011</td>\n      <td>0.968972</td>\n      <td>0.942160</td>\n    </tr>\n    <tr>\n      <th>2023-12-06</th>\n      <td>0.982699</td>\n      <td>0.960798</td>\n      <td>0.961659</td>\n      <td>0.985011</td>\n      <td>0.968972</td>\n      <td>0.929582</td>\n    </tr>\n    <tr>\n      <th>2023-12-07</th>\n      <td>0.982636</td>\n      <td>0.959145</td>\n      <td>0.959470</td>\n      <td>0.984746</td>\n      <td>0.968191</td>\n      <td>0.930242</td>\n    </tr>\n    <tr>\n      <th>2023-12-08</th>\n      <td>0.982470</td>\n      <td>0.958867</td>\n      <td>0.958983</td>\n      <td>0.984636</td>\n      <td>0.968036</td>\n      <td>0.906393</td>\n    </tr>\n    <tr>\n      <th>2023-12-11</th>\n      <td>0.984259</td>\n      <td>0.961341</td>\n      <td>0.961938</td>\n      <td>0.984094</td>\n      <td>0.968233</td>\n      <td>0.949765</td>\n    </tr>\n    <tr>\n      <th>2023-12-12</th>\n      <td>0.984089</td>\n      <td>0.961058</td>\n      <td>0.961443</td>\n      <td>0.983980</td>\n      <td>0.968075</td>\n      <td>0.957548</td>\n    </tr>\n    <tr>\n      <th>2023-12-13</th>\n      <td>0.981061</td>\n      <td>0.957954</td>\n      <td>0.952901</td>\n      <td>0.981144</td>\n      <td>0.964788</td>\n      <td>0.948730</td>\n    </tr>\n    <tr>\n      <th>2023-12-14</th>\n      <td>0.980894</td>\n      <td>0.957674</td>\n      <td>0.952413</td>\n      <td>0.981036</td>\n      <td>0.964637</td>\n      <td>0.958100</td>\n    </tr>\n    <tr>\n      <th>2023-12-15</th>\n      <td>0.979370</td>\n      <td>0.954958</td>\n      <td>0.949250</td>\n      <td>0.980868</td>\n      <td>0.963878</td>\n      <td>0.939669</td>\n    </tr>\n    <tr>\n      <th>2023-12-18</th>\n      <td>0.975625</td>\n      <td>0.947206</td>\n      <td>0.943937</td>\n      <td>0.982323</td>\n      <td>0.962786</td>\n      <td>0.945398</td>\n    </tr>\n    <tr>\n      <th>2023-12-19</th>\n      <td>0.975298</td>\n      <td>0.946659</td>\n      <td>0.942993</td>\n      <td>0.982104</td>\n      <td>0.962456</td>\n      <td>0.932332</td>\n    </tr>\n    <tr>\n      <th>2023-12-20</th>\n      <td>0.972542</td>\n      <td>0.943056</td>\n      <td>0.935203</td>\n      <td>0.980208</td>\n      <td>0.959929</td>\n      <td>0.921403</td>\n    </tr>\n    <tr>\n      <th>2023-12-21</th>\n      <td>0.972381</td>\n      <td>0.942787</td>\n      <td>0.934728</td>\n      <td>0.980099</td>\n      <td>0.959761</td>\n      <td>0.916956</td>\n    </tr>\n    <tr>\n      <th>2023-12-22</th>\n      <td>0.972381</td>\n      <td>0.942787</td>\n      <td>0.934728</td>\n      <td>0.980099</td>\n      <td>0.959761</td>\n      <td>0.917415</td>\n    </tr>\n    <tr>\n      <th>2023-12-25</th>\n      <td>0.972381</td>\n      <td>0.942787</td>\n      <td>0.934728</td>\n      <td>0.980099</td>\n      <td>0.959761</td>\n      <td>0.909602</td>\n    </tr>\n    <tr>\n      <th>2023-12-26</th>\n      <td>0.970226</td>\n      <td>0.939186</td>\n      <td>0.930754</td>\n      <td>0.979564</td>\n      <td>0.958438</td>\n      <td>0.891284</td>\n    </tr>\n    <tr>\n      <th>2023-12-27</th>\n      <td>0.971734</td>\n      <td>0.942917</td>\n      <td>0.931074</td>\n      <td>0.979540</td>\n      <td>0.958349</td>\n      <td>0.906690</td>\n    </tr>\n    <tr>\n      <th>2023-12-28</th>\n      <td>0.971412</td>\n      <td>0.942377</td>\n      <td>0.930142</td>\n      <td>0.979322</td>\n      <td>0.957978</td>\n      <td>0.887815</td>\n    </tr>\n    <tr>\n      <th>2023-12-29</th>\n      <td>0.971412</td>\n      <td>0.942377</td>\n      <td>0.930142</td>\n      <td>0.979322</td>\n      <td>0.957978</td>\n      <td>0.896761</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result /= 1e6\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T10:12:30.322228Z",
     "start_time": "2024-02-26T10:12:30.011338200Z"
    }
   },
   "id": "ad47f38f4a67af56",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "result.to_csv(f\"DRL/ccso_{TRADE_START_DATE}_{TRADE_END_DATE}.csv\", index=None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T10:12:30.434426200Z",
     "start_time": "2024-02-26T10:12:30.111116500Z"
    }
   },
   "id": "3079d1cd0c86a43c",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Axes: xlabel='date'>"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 1500x500 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1500x500 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "plt.figure()\n",
    "result.plot()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T10:12:31.344520700Z",
     "start_time": "2024-02-26T10:12:30.209976400Z"
    }
   },
   "id": "ca02e9f1bfc4c9d4",
   "execution_count": 50
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
